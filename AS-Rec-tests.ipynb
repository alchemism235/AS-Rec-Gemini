{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac0e2d8-cae5-4417-a70a-94e581ed715a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 451185\n",
      "학습 데이터 수: 315829 (70.00%)\n",
      "검증 데이터 수: 45119 (10.00%)\n",
      "테스트 데이터 수: 90237 (20.00%)\n",
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "Applying pre-selected Best Parameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "==================================================\n",
      "\n",
      "--- Training Final Model with Best Parameters ---\n",
      "Final Train Epoch 1/50, Train Loss: 0.7284, Val RMSE: 0.7046\n",
      "  --> RMSE improved. Model saved: 0.7046\n",
      "Final Train Epoch 2/50, Train Loss: 0.4770, Val RMSE: 0.6902\n",
      "  --> RMSE improved. Model saved: 0.6902\n",
      "Final Train Epoch 3/50, Train Loss: 0.4411, Val RMSE: 0.6864\n",
      "  --> RMSE improved. Model saved: 0.6864\n",
      "Final Train Epoch 4/50, Train Loss: 0.4118, Val RMSE: 0.7170\n",
      "  --> RMSE not improved. (1/10)\n",
      "Final Train Epoch 5/50, Train Loss: 0.3887, Val RMSE: 0.6884\n",
      "  --> RMSE not improved. (2/10)\n",
      "Final Train Epoch 6/50, Train Loss: 0.3658, Val RMSE: 0.7025\n",
      "  --> RMSE not improved. (3/10)\n",
      "Final Train Epoch 7/50, Train Loss: 0.3435, Val RMSE: 0.7066\n",
      "  --> RMSE not improved. (4/10)\n",
      "Final Train Epoch 8/50, Train Loss: 0.3203, Val RMSE: 0.7276\n",
      "  --> RMSE not improved. (5/10)\n",
      "Final Train Epoch 9/50, Train Loss: 0.2949, Val RMSE: 0.7233\n",
      "  --> RMSE not improved. (6/10)\n",
      "Final Train Epoch 10/50, Train Loss: 0.2695, Val RMSE: 0.7379\n",
      "  --> RMSE not improved. (7/10)\n",
      "Final Train Epoch 11/50, Train Loss: 0.2441, Val RMSE: 0.7476\n",
      "  --> RMSE not improved. (8/10)\n",
      "Final Train Epoch 12/50, Train Loss: 0.2196, Val RMSE: 0.7684\n",
      "  --> RMSE not improved. (9/10)\n",
      "Final Train Epoch 13/50, Train Loss: 0.1985, Val RMSE: 0.7668\n",
      "  --> RMSE not improved. (10/10)\n",
      "Early stopping - No validation RMSE improvement for 10 epochs.\n",
      "\n",
      "--- Evaluating Final Model on Test Set ---\n",
      "Loaded best model weights from final_best_aat_rec_model.pt\n",
      "\n",
      "--- Performance Evaluation (Final Model with Best Parameters) ---\n",
      "Selected Hyperparameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "Mean Squared Error (MSE): 0.4768\n",
      "Root Mean Squared Error (RMSE): 0.6905\n",
      "Mean Absolute Error (MAE): 0.5396\n",
      "Mean Absolute Percentage Error (MAPE): 19.61%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# --- 1. Utility Functions ---\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return 0.0 # 모든 y_true가 0인 경우 MAPE는 0으로 처리\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "\n",
    "# 파일 로드\n",
    "# IMPORTANT: Adjust this path to where your JSON file is located on your local machine.\n",
    "df = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "\n",
    "# 필요한 컬럼 추출\n",
    "df_processed = df[['user_id', 'business_id', 'stars', 'sentiment_vector']].copy()\n",
    "\n",
    "# user_id와 business_id를 연속적인 정수 ID로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "df_processed.loc[:, 'user_encoded'] = user_encoder.fit_transform(df_processed['user_id'])\n",
    "df_processed.loc[:, 'business_encoded'] = business_encoder.fit_transform(df_processed['business_id'])\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "# 데이터 분할\n",
    "# 논문에서 제시된 70/10/20 비율로 데이터 분할\n",
    "train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "val_size_ratio = 1 / 8 # 10% of total data (1/8 of 80%)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42)\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "print(f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\")\n",
    "\n",
    "# Determine sentiment_vector_dim dynamically\n",
    "sentiment_vector_dim = len(df_processed['sentiment_vector'].iloc[0]) if not df_processed.empty else 15\n",
    "\n",
    "# --- 3. PyTorch Dataset and DataLoader Definition ---\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_encoded'].values, dtype=torch.long)\n",
    "        self.business_ids = torch.tensor(df['business_encoded'].values, dtype=torch.long)\n",
    "        self.sentiment_vectors = torch.tensor(np.array(df['sentiment_vector'].tolist()), dtype=torch.float)\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.business_ids[idx], self.sentiment_vectors[idx], self.stars[idx]\n",
    "\n",
    "# --- 4. Model Architecture Definition ---\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = mlp_dims[-1] if mlp_dims else embedding_dim * 2\n",
    "\n",
    "    def forward(self, user_ids, business_ids):\n",
    "        user_vec = self.user_embedding(user_ids)\n",
    "        business_vec = self.business_embedding(business_ids)\n",
    "        combined_vec = torch.cat((user_vec, business_vec), dim=1)\n",
    "        interaction_features = self.mlp(combined_vec)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectModule(nn.Module):\n",
    "    def __init__(self, sentiment_vector_dim, aspect_mlp_dims):\n",
    "        super(ReviewAspectModule, self).__init__()\n",
    "        layers = []\n",
    "        input_dim = sentiment_vector_dim\n",
    "        for dim in aspect_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = aspect_mlp_dims[-1] if aspect_mlp_dims else sentiment_vector_dim\n",
    "\n",
    "    def forward(self, sentiment_vectors):\n",
    "        aspect_features = self.mlp(sentiment_vectors)\n",
    "        return aspect_features\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                     user_biz_mlp_dims, aspect_mlp_dims, final_mlp_dims,\n",
    "                     sentiment_vector_dim):\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_interaction_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims\n",
    "        )\n",
    "        self.review_aspect_module = ReviewAspectModule(\n",
    "            sentiment_vector_dim, aspect_mlp_dims\n",
    "        )\n",
    "\n",
    "        final_input_dim = self.customer_restaurant_interaction_module.output_dim + \\\n",
    "                              self.review_aspect_module.output_dim\n",
    "\n",
    "        layers = []\n",
    "        input_dim = final_input_dim\n",
    "        for dim in final_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1)) # Final output is rating (1-dimensional)\n",
    "        self.prediction_mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, user_ids, business_ids, sentiment_vectors):\n",
    "        user_biz_features = self.customer_restaurant_interaction_module(user_ids, business_ids)\n",
    "        aspect_features = self.review_aspect_module(sentiment_vectors)\n",
    "        combined_features = torch.cat((user_biz_features, aspect_features), dim=1)\n",
    "        predicted_rating = self.prediction_mlp(combined_features)\n",
    "        return predicted_rating.squeeze() # Return 1D rating\n",
    "\n",
    "# --- 5. Device Configuration (GPU Setup) ---\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 6. Dataset and DataLoader Creation ---\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df)\n",
    "\n",
    "# --- 7. Apply the Given Best Parameters ---\n",
    "# Previously, these were found via grid search. Now, we explicitly set them.\n",
    "best_params = {\n",
    "    'aspect_mlp_hidden_dims': [64, 32],\n",
    "    'batch_size': 128,\n",
    "    'embedding_dim': 64,\n",
    "    'final_mlp_hidden_dims': [32, 16],\n",
    "    'learning_rate': 0.001,\n",
    "    'user_biz_mlp_hidden_dims': [128, 64]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Applying pre-selected Best Parameters: {best_params}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 8. Final Model Training and Testing (Using Best Parameters) ---\n",
    "final_embedding_dim = best_params['embedding_dim']\n",
    "final_learning_rate = best_params['learning_rate']\n",
    "final_batch_size = best_params['batch_size']\n",
    "final_user_biz_mlp_dims = best_params['user_biz_mlp_hidden_dims']\n",
    "final_aspect_mlp_dims = best_params['aspect_mlp_hidden_dims']\n",
    "final_final_mlp_dims = best_params['final_mlp_hidden_dims']\n",
    "\n",
    "final_model = AATRec(num_users, num_businesses, final_embedding_dim,\n",
    "                     final_user_biz_mlp_dims, final_aspect_mlp_dims, final_final_mlp_dims,\n",
    "                     sentiment_vector_dim).to(device) # Move final model to device\n",
    "\n",
    "final_criterion = nn.MSELoss()\n",
    "final_optimizer = optim.Adam(final_model.parameters(), lr=final_learning_rate)\n",
    "\n",
    "final_train_loader = DataLoader(train_dataset, batch_size=final_batch_size, shuffle=True)\n",
    "final_val_loader = DataLoader(val_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "final_test_loader = DataLoader(test_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "\n",
    "final_epochs = 50 # Ample epochs for final training\n",
    "final_patience = 10 # More patience for final training\n",
    "final_min_delta = 0.0005 # Stricter improvement criterion\n",
    "\n",
    "best_final_val_rmse = float('inf')\n",
    "epochs_no_improve_final = 0\n",
    "final_model_path = 'final_best_aat_rec_model.pt'\n",
    "\n",
    "print(\"\\n--- Training Final Model with Best Parameters ---\")\n",
    "for epoch in range(final_epochs):\n",
    "    # Training phase\n",
    "    final_model.train()\n",
    "    total_train_loss = 0\n",
    "    for user_ids, business_ids, sentiment_vectors, stars in final_train_loader:\n",
    "        user_ids, business_ids, sentiment_vectors, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), stars.to(device)\n",
    "\n",
    "        final_optimizer.zero_grad()\n",
    "        predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "        loss = final_criterion(predictions, stars)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    final_model.eval()\n",
    "    val_predictions = []\n",
    "    val_true_ratings = []\n",
    "    with torch.no_grad():\n",
    "        for user_ids, business_ids, sentiment_vectors, stars in final_val_loader:\n",
    "            user_ids, business_ids, sentiment_vectors, stars = \\\n",
    "                user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), stars.to(device)\n",
    "\n",
    "            predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "            val_predictions.extend(predictions.cpu().tolist())\n",
    "            val_true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true_ratings, val_predictions))\n",
    "\n",
    "    print(f\"Final Train Epoch {epoch+1}/{final_epochs}, \"\n",
    "          f\"Train Loss: {total_train_loss / len(final_train_loader):.4f}, \"\n",
    "          f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "    # Early stopping logic for final model\n",
    "    if current_val_rmse < best_final_val_rmse - final_min_delta:\n",
    "        best_final_val_rmse = current_val_rmse\n",
    "        epochs_no_improve_final = 0\n",
    "        torch.save(final_model.state_dict(), final_model_path)\n",
    "        print(f\"  --> RMSE improved. Model saved: {best_final_val_rmse:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve_final += 1\n",
    "        print(f\"  --> RMSE not improved. ({epochs_no_improve_final}/{final_patience})\")\n",
    "        if epochs_no_improve_final == final_patience:\n",
    "            print(f\"Early stopping - No validation RMSE improvement for {final_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "# --- 9. Final Model Testing ---\n",
    "print(\"\\n--- Evaluating Final Model on Test Set ---\")\n",
    "if os.path.exists(final_model_path):\n",
    "    final_model.load_state_dict(torch.load(final_model_path))\n",
    "    print(f\"Loaded best model weights from {final_model_path}\")\n",
    "else:\n",
    "    print(f\"Could not find optimal final model weights at '{final_model_path}'. Testing with current model state.\")\n",
    "\n",
    "final_model.eval()\n",
    "test_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_ids, business_ids, sentiment_vectors, stars in final_test_loader:\n",
    "        user_ids, business_ids, sentiment_vectors, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), stars.to(device)\n",
    "\n",
    "        predictions = final_model(user_ids, business_ids, sentiment_vectors)\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "mse = mean_squared_error(true_ratings, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "\n",
    "print(f\"\\n--- Performance Evaluation (Final Model with Best Parameters) ---\")\n",
    "print(f\"Selected Hyperparameters: {best_params}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Clean up temporary models directory if it was created by the original script\n",
    "if os.path.exists('temp_models'):\n",
    "    import shutil\n",
    "    shutil.rmtree('temp_models')\n",
    "    print(\"\\nCleaned up 'temp_models' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99302219-41f8-4c28-94bf-2029b2a7dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing embeddings from 'review_business_5up_with_embedded_vector.jsonl' and saving to 'review_business_5up_with_reduced_embedding.jsonl'...\n",
      "Reducing from 3072 to 32 dimensions in batches of 1024.\n",
      "Processed 1024 lines...\n",
      "Processed 2048 lines...\n",
      "Processed 3072 lines...\n",
      "Processed 4096 lines...\n",
      "Processed 5120 lines...\n",
      "Processed 6144 lines...\n",
      "Processed 7168 lines...\n",
      "Processed 8192 lines...\n",
      "Processed 9216 lines...\n",
      "Processed 10240 lines...\n",
      "Processed 11264 lines...\n",
      "Processed 12288 lines...\n",
      "Processed 13312 lines...\n",
      "Processed 14336 lines...\n",
      "Processed 15360 lines...\n",
      "Processed 16384 lines...\n",
      "Processed 17408 lines...\n",
      "Processed 18432 lines...\n",
      "Processed 19456 lines...\n",
      "Processed 20480 lines...\n",
      "Processed 21504 lines...\n",
      "Processed 22528 lines...\n",
      "Processed 23552 lines...\n",
      "Processed 24576 lines...\n",
      "Processed 25600 lines...\n",
      "Processed 26624 lines...\n",
      "Processed 27648 lines...\n",
      "Processed 28672 lines...\n",
      "Processed 29696 lines...\n",
      "Processed 30720 lines...\n",
      "Processed 31744 lines...\n",
      "Processed 32768 lines...\n",
      "Processed 33792 lines...\n",
      "Processed 34816 lines...\n",
      "Processed 35840 lines...\n",
      "Processed 36864 lines...\n",
      "Processed 37888 lines...\n",
      "Processed 38912 lines...\n",
      "Processed 39936 lines...\n",
      "Processed 40960 lines...\n",
      "Processed 41984 lines...\n",
      "Processed 43008 lines...\n",
      "Processed 44032 lines...\n",
      "Processed 45056 lines...\n",
      "Processed 46080 lines...\n",
      "Processed 47104 lines...\n",
      "Processed 48128 lines...\n",
      "Processed 49152 lines...\n",
      "Processed 50176 lines...\n",
      "Processed 51200 lines...\n",
      "Processed 52224 lines...\n",
      "Processed 53248 lines...\n",
      "Processed 54272 lines...\n",
      "Processed 55296 lines...\n",
      "Processed 56320 lines...\n",
      "Processed 57344 lines...\n",
      "Processed 58368 lines...\n",
      "Processed 59392 lines...\n",
      "Processed 60416 lines...\n",
      "Processed 61440 lines...\n",
      "Processed 62464 lines...\n",
      "Processed 63488 lines...\n",
      "Processed 64512 lines...\n",
      "Processed 65536 lines...\n",
      "Processed 66560 lines...\n",
      "Processed 67584 lines...\n",
      "Processed 68608 lines...\n",
      "Processed 69632 lines...\n",
      "Processed 70656 lines...\n",
      "Processed 71680 lines...\n",
      "Processed 72704 lines...\n",
      "Processed 73728 lines...\n",
      "Processed 74752 lines...\n",
      "Processed 75776 lines...\n",
      "Processed 76800 lines...\n",
      "Processed 77824 lines...\n",
      "Processed 78848 lines...\n",
      "Processed 79872 lines...\n",
      "Processed 80896 lines...\n",
      "Processed 81920 lines...\n",
      "Processed 82944 lines...\n",
      "Processed 83968 lines...\n",
      "Processed 84992 lines...\n",
      "Processed 86016 lines...\n",
      "Processed 87040 lines...\n",
      "Processed 88064 lines...\n",
      "Processed 89088 lines...\n",
      "Processed 90112 lines...\n",
      "Processed 91136 lines...\n",
      "Processed 92160 lines...\n",
      "Processed 93184 lines...\n",
      "Processed 94208 lines...\n",
      "Processed 95232 lines...\n",
      "Processed 96256 lines...\n",
      "Processed 97280 lines...\n",
      "Processed 98304 lines...\n",
      "Processed 99328 lines...\n",
      "Processed 100352 lines...\n",
      "Processed 101376 lines...\n",
      "Processed 102400 lines...\n",
      "Processed 103424 lines...\n",
      "Processed 104448 lines...\n",
      "Processed 105472 lines...\n",
      "Processed 106496 lines...\n",
      "Processed 107520 lines...\n",
      "Processed 108544 lines...\n",
      "Processed 109568 lines...\n",
      "Processed 110592 lines...\n",
      "Processed 111616 lines...\n",
      "Processed 112640 lines...\n",
      "Processed 113664 lines...\n",
      "Processed 114688 lines...\n",
      "Processed 115712 lines...\n",
      "Processed 116736 lines...\n",
      "Processed 117760 lines...\n",
      "Processed 118784 lines...\n",
      "Processed 119808 lines...\n",
      "Processed 120832 lines...\n",
      "Processed 121856 lines...\n",
      "Processed 122880 lines...\n",
      "Processed 123904 lines...\n",
      "Processed 124928 lines...\n",
      "Processed 125952 lines...\n",
      "Processed 126976 lines...\n",
      "Processed 128000 lines...\n",
      "Processed 129024 lines...\n",
      "Processed 130048 lines...\n",
      "Processed 131072 lines...\n",
      "Processed 132096 lines...\n",
      "Processed 133120 lines...\n",
      "Processed 134144 lines...\n",
      "Processed 135168 lines...\n",
      "Processed 136192 lines...\n",
      "Processed 137216 lines...\n",
      "Processed 138240 lines...\n",
      "Processed 139264 lines...\n",
      "Processed 140288 lines...\n",
      "Processed 141312 lines...\n",
      "Processed 142336 lines...\n",
      "Processed 143360 lines...\n",
      "Processed 144384 lines...\n",
      "Processed 145408 lines...\n",
      "Processed 146432 lines...\n",
      "Processed 147456 lines...\n",
      "Processed 148480 lines...\n",
      "Processed 149504 lines...\n",
      "Processed 150528 lines...\n",
      "Processed 151552 lines...\n",
      "Processed 152576 lines...\n",
      "Processed 153600 lines...\n",
      "Processed 154624 lines...\n",
      "Processed 155648 lines...\n",
      "Processed 156672 lines...\n",
      "Processed 157696 lines...\n",
      "Processed 158720 lines...\n",
      "Processed 159744 lines...\n",
      "Processed 160768 lines...\n",
      "Processed 161792 lines...\n",
      "Processed 162816 lines...\n",
      "Processed 163840 lines...\n",
      "Processed 164864 lines...\n",
      "Processed 165888 lines...\n",
      "Processed 166912 lines...\n",
      "Processed 167936 lines...\n",
      "Processed 168960 lines...\n",
      "Processed 169984 lines...\n",
      "Processed 171008 lines...\n",
      "Processed 172032 lines...\n",
      "Processed 173056 lines...\n",
      "Processed 174080 lines...\n",
      "Processed 175104 lines...\n",
      "Processed 176128 lines...\n",
      "Processed 177152 lines...\n",
      "Processed 178176 lines...\n",
      "Processed 179200 lines...\n",
      "Processed 180224 lines...\n",
      "Processed 181248 lines...\n",
      "Processed 182272 lines...\n",
      "Processed 183296 lines...\n",
      "Processed 184320 lines...\n",
      "Processed 185344 lines...\n",
      "Processed 186368 lines...\n",
      "Processed 187392 lines...\n",
      "Processed 188416 lines...\n",
      "Processed 189440 lines...\n",
      "Processed 190464 lines...\n",
      "Processed 191488 lines...\n",
      "Processed 192512 lines...\n",
      "Processed 193536 lines...\n",
      "Processed 194560 lines...\n",
      "Processed 195584 lines...\n",
      "Processed 196608 lines...\n",
      "Processed 197632 lines...\n",
      "Processed 198656 lines...\n",
      "Processed 199680 lines...\n",
      "Processed 200704 lines...\n",
      "Processed 201728 lines...\n",
      "Processed 202752 lines...\n",
      "Processed 203776 lines...\n",
      "Processed 204800 lines...\n",
      "Processed 205824 lines...\n",
      "Processed 206848 lines...\n",
      "Processed 207872 lines...\n",
      "Processed 208896 lines...\n",
      "Processed 209920 lines...\n",
      "Processed 210944 lines...\n",
      "Processed 211968 lines...\n",
      "Processed 212992 lines...\n",
      "Processed 214016 lines...\n",
      "Processed 215040 lines...\n",
      "Processed 216064 lines...\n",
      "Processed 217088 lines...\n",
      "Processed 218112 lines...\n",
      "Processed 219136 lines...\n",
      "Processed 220160 lines...\n",
      "Processed 221184 lines...\n",
      "Processed 222208 lines...\n",
      "Processed 223232 lines...\n",
      "Processed 224256 lines...\n",
      "Processed 225280 lines...\n",
      "Processed 226304 lines...\n",
      "Processed 227328 lines...\n",
      "Processed 228352 lines...\n",
      "Processed 229376 lines...\n",
      "Processed 230400 lines...\n",
      "Processed 231424 lines...\n",
      "Processed 232448 lines...\n",
      "Processed 233472 lines...\n",
      "Processed 234496 lines...\n",
      "Processed 235520 lines...\n",
      "Processed 236544 lines...\n",
      "Processed 237568 lines...\n",
      "Processed 238592 lines...\n",
      "Processed 239616 lines...\n",
      "Processed 240640 lines...\n",
      "Processed 241664 lines...\n",
      "Processed 242688 lines...\n",
      "Processed 243712 lines...\n",
      "Processed 244736 lines...\n",
      "Processed 245760 lines...\n",
      "Processed 246784 lines...\n",
      "Processed 247808 lines...\n",
      "Processed 248832 lines...\n",
      "Processed 249856 lines...\n",
      "Processed 250880 lines...\n",
      "Processed 251904 lines...\n",
      "Processed 252928 lines...\n",
      "Processed 253952 lines...\n",
      "Processed 254976 lines...\n",
      "Processed 256000 lines...\n",
      "Processed 257024 lines...\n",
      "Processed 258048 lines...\n",
      "Processed 259072 lines...\n",
      "Processed 260096 lines...\n",
      "Processed 261120 lines...\n",
      "Processed 262144 lines...\n",
      "Processed 263168 lines...\n",
      "Processed 264192 lines...\n",
      "Processed 265216 lines...\n",
      "Processed 266240 lines...\n",
      "Processed 267264 lines...\n",
      "Processed 268288 lines...\n",
      "Processed 269312 lines...\n",
      "Processed 270336 lines...\n",
      "Processed 271360 lines...\n",
      "Processed 272384 lines...\n",
      "Processed 273408 lines...\n",
      "Processed 274432 lines...\n",
      "Processed 275456 lines...\n",
      "Processed 276480 lines...\n",
      "Processed 277504 lines...\n",
      "Processed 278528 lines...\n",
      "Processed 279552 lines...\n",
      "Processed 280576 lines...\n",
      "Processed 281600 lines...\n",
      "Processed 282624 lines...\n",
      "Processed 283648 lines...\n",
      "Processed 284672 lines...\n",
      "Processed 285696 lines...\n",
      "Processed 286720 lines...\n",
      "Processed 287744 lines...\n",
      "Processed 288768 lines...\n",
      "Processed 289792 lines...\n",
      "Processed 290816 lines...\n",
      "Processed 291840 lines...\n",
      "Processed 292864 lines...\n",
      "Processed 293888 lines...\n",
      "Processed 294912 lines...\n",
      "Processed 295936 lines...\n",
      "Processed 296960 lines...\n",
      "Processed 297984 lines...\n",
      "Processed 299008 lines...\n",
      "Processed 300032 lines...\n",
      "Processed 301056 lines...\n",
      "Processed 302080 lines...\n",
      "Processed 303104 lines...\n",
      "Processed 304128 lines...\n",
      "Processed 305152 lines...\n",
      "Processed 306176 lines...\n",
      "Processed 307200 lines...\n",
      "Processed 308224 lines...\n",
      "Processed 309248 lines...\n",
      "Processed 310272 lines...\n",
      "Processed 311296 lines...\n",
      "Processed 312320 lines...\n",
      "Processed 313344 lines...\n",
      "Processed 314368 lines...\n",
      "Processed 315392 lines...\n",
      "Processed 316416 lines...\n",
      "Processed 317440 lines...\n",
      "Processed 318464 lines...\n",
      "Processed 319488 lines...\n",
      "Processed 320512 lines...\n",
      "Processed 321536 lines...\n",
      "Processed 322560 lines...\n",
      "Processed 323584 lines...\n",
      "Processed 324608 lines...\n",
      "Processed 325632 lines...\n",
      "Processed 326656 lines...\n",
      "Processed 327680 lines...\n",
      "Processed 328704 lines...\n",
      "Processed 329728 lines...\n",
      "Processed 330752 lines...\n",
      "Processed 331776 lines...\n",
      "Processed 332800 lines...\n",
      "Processed 333824 lines...\n",
      "Processed 334848 lines...\n",
      "Processed 335872 lines...\n",
      "Processed 336896 lines...\n",
      "Processed 337920 lines...\n",
      "Processed 338944 lines...\n",
      "Processed 339968 lines...\n",
      "Processed 340992 lines...\n",
      "Processed 342016 lines...\n",
      "Processed 343040 lines...\n",
      "Processed 344064 lines...\n",
      "Processed 345088 lines...\n",
      "Processed 346112 lines...\n",
      "Processed 347136 lines...\n",
      "Processed 348160 lines...\n",
      "Processed 349184 lines...\n",
      "Processed 350208 lines...\n",
      "Processed 351232 lines...\n",
      "Processed 352256 lines...\n",
      "Processed 353280 lines...\n",
      "Processed 354304 lines...\n",
      "Processed 355328 lines...\n",
      "Processed 356352 lines...\n",
      "Processed 357376 lines...\n",
      "Processed 358400 lines...\n",
      "Processed 359424 lines...\n",
      "Processed 360448 lines...\n",
      "Processed 361472 lines...\n",
      "Processed 362496 lines...\n",
      "Processed 363520 lines...\n",
      "Processed 364544 lines...\n",
      "Processed 365568 lines...\n",
      "Processed 366592 lines...\n",
      "Processed 367616 lines...\n",
      "Processed 368640 lines...\n",
      "Processed 369664 lines...\n",
      "Processed 370688 lines...\n",
      "Processed 371712 lines...\n",
      "Processed 372736 lines...\n",
      "Processed 373760 lines...\n",
      "Processed 374784 lines...\n",
      "Processed 375808 lines...\n",
      "Processed 376832 lines...\n",
      "Processed 377856 lines...\n",
      "Processed 378880 lines...\n",
      "Processed 379904 lines...\n",
      "Processed 380928 lines...\n",
      "Processed 381952 lines...\n",
      "Processed 382976 lines...\n",
      "Processed 384000 lines...\n",
      "Processed 385024 lines...\n",
      "Processed 386048 lines...\n",
      "Processed 387072 lines...\n",
      "Processed 388096 lines...\n",
      "Processed 389120 lines...\n",
      "Processed 390144 lines...\n",
      "Processed 391168 lines...\n",
      "Processed 392192 lines...\n",
      "Processed 393216 lines...\n",
      "Processed 394240 lines...\n",
      "Processed 395264 lines...\n",
      "Processed 396288 lines...\n",
      "Processed 397312 lines...\n",
      "Processed 398336 lines...\n",
      "Processed 399360 lines...\n",
      "Processed 400384 lines...\n",
      "Processed 401408 lines...\n",
      "Processed 402432 lines...\n",
      "Processed 403456 lines...\n",
      "Processed 404480 lines...\n",
      "Processed 405504 lines...\n",
      "Processed 406528 lines...\n",
      "Processed 407552 lines...\n",
      "Processed 408576 lines...\n",
      "Processed 409600 lines...\n",
      "Processed 410624 lines...\n",
      "Processed 411648 lines...\n",
      "Processed 412672 lines...\n",
      "Processed 413696 lines...\n",
      "Processed 414720 lines...\n",
      "Processed 415744 lines...\n",
      "Processed 416768 lines...\n",
      "Processed 417792 lines...\n",
      "Processed 418816 lines...\n",
      "Processed 419840 lines...\n",
      "Processed 420864 lines...\n",
      "Processed 421888 lines...\n",
      "Processed 422912 lines...\n",
      "Processed 423936 lines...\n",
      "Processed 424960 lines...\n",
      "Processed 425984 lines...\n",
      "Processed 427008 lines...\n",
      "Processed 428032 lines...\n",
      "Processed 429056 lines...\n",
      "Processed 430080 lines...\n",
      "Processed 431104 lines...\n",
      "Processed 432128 lines...\n",
      "Processed 433152 lines...\n",
      "Processed 434176 lines...\n",
      "Processed 435200 lines...\n",
      "Processed 436224 lines...\n",
      "Processed 437248 lines...\n",
      "Processed 438272 lines...\n",
      "Processed 439296 lines...\n",
      "Processed 440320 lines...\n",
      "Processed 441344 lines...\n",
      "Processed 442368 lines...\n",
      "Processed 443392 lines...\n",
      "Processed 444416 lines...\n",
      "Processed 445440 lines...\n",
      "Processed 446464 lines...\n",
      "Processed 447488 lines...\n",
      "Finished processing all 447796 lines.\n",
      "Embedding reduction and saving complete. Processed data saved to 'review_business_5up_with_reduced_embedding.jsonl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # 여전히 LabelEncoder, DataFrame 초기화 등에 필요하지만, 대용량 파일 로드에는 사용하지 않음\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json # JSONL 파일 처리를 위해 필요\n",
    "import os\n",
    "\n",
    "# --- 1. Dimensionality Reducer MLP Definition ---\n",
    "class DimensionalityReducerMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    3072차원 입력 벡터를 512 -> 128 -> 32차원으로 줄이는 MLP 모듈.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3072, output_dim=32):\n",
    "        super(DimensionalityReducerMLP, self).__init__()\n",
    "        # 첫 번째 선형 레이어: input_dim -> 512\n",
    "        self.layer1 = nn.Linear(input_dim, 512)\n",
    "        # 두 번째 선형 레이어: 512 -> 128\n",
    "        self.layer2 = nn.Linear(512, 128)\n",
    "        # 세 번째 선형 레이어 (최종 출력): 128 -> output_dim\n",
    "        self.layer3 = nn.Linear(128, output_dim)\n",
    "\n",
    "        # 활성화 함수 (ReLU)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x는 입력 벡터 (예: 3072차원)\n",
    "        x = self.relu(self.layer1(x)) # 3072 -> 512, ReLU 적용\n",
    "        x = self.relu(self.layer2(x)) # 512 -> 128, ReLU 적용\n",
    "        x = self.layer3(x)           # 128 -> 32 (최종 출력에는 일반적으로 ReLU 미적용)\n",
    "        return x\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "# 원본 3072차원 임베딩이 포함된 큰 JSONL 파일\n",
    "input_file_path = 'review_business_5up_with_embedded_vector.jsonl'\n",
    "# 32차원으로 축소된 임베딩이 저장될 새로운 JSONL 파일\n",
    "output_file_path = 'review_business_5up_with_reduced_embedding.jsonl'\n",
    "\n",
    "original_embedding_dim = 3072\n",
    "reduced_embedding_dim = 32\n",
    "processing_batch_size = 1024 # 한 번에 처리할 레코드 수 (메모리 상황에 따라 조절)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 3. Initialize MLP Model ---\n",
    "reducer_mlp = DimensionalityReducerMLP(input_dim=original_embedding_dim, output_dim=reduced_embedding_dim).to(device)\n",
    "reducer_mlp.eval() # 추론 모드로 설정 (dropout, batchnorm 등 비활성화)\n",
    "\n",
    "# --- 4. Process Embeddings in Chunks and Save ---\n",
    "print(f\"Processing embeddings from '{input_file_path}' and saving to '{output_file_path}'...\")\n",
    "print(f\"Reducing from {original_embedding_dim} to {reduced_embedding_dim} dimensions in batches of {processing_batch_size}.\")\n",
    "\n",
    "# 파일의 총 라인 수를 미리 세는 과정은 제거 (tqdm 사용 안 하므로)\n",
    "# 이 과정이 너무 오래 걸린다면, total=None으로 설정하여 대략적인 진행률만 표시할 수 있습니다.\n",
    "# try:\n",
    "#     print(\"Counting total lines in the input file... (This might take a while for large files)\")\n",
    "#     with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "#         total_lines = sum(1 for line in f)\n",
    "#     print(f\"Total lines found: {total_lines}\")\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"Error: Input file not found at {input_file_path}. Please check the path.\")\n",
    "#     exit()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error counting lines in input file: {e}\")\n",
    "#     total_lines = None # 총 라인 수를 알 수 없으면 None으로 설정하여 tqdm이 무한 진행률로 표시\n",
    "\n",
    "\n",
    "# 출력 파일을 새로 생성하거나 덮어쓰기 위해 'w' 모드로 엽니다.\n",
    "with open(input_file_path, 'r', encoding='utf-8') as infile, \\\n",
    "     open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "    batch_records = [] # 현재 배치의 원본 레코드를 저장\n",
    "    line_count = 0 # 처리된 라인 수 카운터 추가\n",
    "\n",
    "    for line in infile: # tqdm 제거\n",
    "        line_count += 1\n",
    "        try:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            # 'embedding' 컬럼이 존재하는지 확인\n",
    "            if 'embedding' not in record:\n",
    "                print(f\"Warning: 'embedding' key not found in record (line {line_count}), skipping. Line: {line.strip()}\")\n",
    "                continue\n",
    "            if not isinstance(record['embedding'], list) or len(record['embedding']) == 0:\n",
    "                print(f\"Warning: 'embedding' is not a valid list or is empty (line {line_count}), skipping. Line: {line.strip()}\")\n",
    "                continue\n",
    "            \n",
    "            # 실제 임베딩 차원 확인 (첫 번째 레코드에서만 경고)\n",
    "            if line_count == 1 and len(record['embedding']) != original_embedding_dim:\n",
    "                 print(f\"Warning: Expected embedding dimension is {original_embedding_dim}, but found {len(record['embedding'])}.\")\n",
    "                 print(\"Please ensure 'original_embedding_dim' matches your actual embedding dimension.\")\n",
    "\n",
    "            batch_records.append(record)\n",
    "\n",
    "            if len(batch_records) >= processing_batch_size:\n",
    "                # 배치 처리\n",
    "                embeddings_to_process = torch.tensor(\n",
    "                    np.array([d['embedding'] for d in batch_records]), dtype=torch.float\n",
    "                ).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    reduced_embeddings = reducer_mlp(embeddings_to_process).cpu().tolist()\n",
    "\n",
    "                # 원본 데이터에 축소된 임베딩 추가 및 저장\n",
    "                for i, d in enumerate(batch_records):\n",
    "                    d['reduced_embedding'] = reduced_embeddings[i]\n",
    "                    if 'embedding' in d:\n",
    "                        del d['embedding']\n",
    "                    outfile.write(json.dumps(d, ensure_ascii=False) + '\\n')\n",
    "                batch_records = [] # 배치 초기화\n",
    "                print(f\"Processed {line_count} lines...\") # 진행 상황 출력\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Skipping malformed JSON line (line {line_count}): {line.strip()} - Error: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred (line {line_count}): {e} in line: {line.strip()}\")\n",
    "            continue\n",
    "\n",
    "    # 남은 데이터 처리 (마지막 배치)\n",
    "    if batch_records:\n",
    "        embeddings_to_process = torch.tensor(\n",
    "            np.array([d['embedding'] for d in batch_records]), dtype=torch.float\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            reduced_embeddings = reducer_mlp(embeddings_to_process).cpu().tolist()\n",
    "\n",
    "        for i, d in enumerate(batch_records):\n",
    "            d['reduced_embedding'] = reduced_embeddings[i]\n",
    "            if 'embedding' in d:\n",
    "                del d['embedding']\n",
    "            outfile.write(json.dumps(d, ensure_ascii=False) + '\\n')\n",
    "    print(f\"Finished processing all {line_count} lines.\")\n",
    "\n",
    "print(f\"Embedding reduction and saving complete. Processed data saved to '{output_file_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1258db-b08b-429e-bf2f-eef0390e17f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment data from 'review_business_5up_5aspect_3sentiment_vectorized_clean.json'...\n",
      "Sentiment data loaded. Total records: 447796\n",
      "Loading reduced embedding data from 'review_business_5up_with_reduced_embedding.jsonl'...\n",
      "Reduced embedding data loaded. Total records: 447796\n",
      "Data merged successfully. Total processed records: 447796\n",
      "전체 데이터 수: 447796\n",
      "학습 데이터 수: 313456 (70.00%)\n",
      "검증 데이터 수: 44780 (10.00%)\n",
      "테스트 데이터 수: 89560 (20.00%)\n",
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "Applying pre-selected Best Parameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "==================================================\n",
      "\n",
      "--- Training Final Model with Best Parameters ---\n",
      "Epoch 1/50, Train Loss (Avg): 0.6682, Val RMSE: 0.7050\n",
      "  --> RMSE improved. Model saved: 0.7050\n",
      "Epoch 2/50, Train Loss (Avg): 0.4715, Val RMSE: 0.7007\n",
      "  --> RMSE improved. Model saved: 0.7007\n",
      "Epoch 3/50, Train Loss (Avg): 0.4326, Val RMSE: 0.6832\n",
      "  --> RMSE improved. Model saved: 0.6832\n",
      "Epoch 4/50, Train Loss (Avg): 0.4013, Val RMSE: 0.6827\n",
      "  --> RMSE not improved. (1/10)\n",
      "Epoch 5/50, Train Loss (Avg): 0.3738, Val RMSE: 0.6752\n",
      "  --> RMSE improved. Model saved: 0.6752\n",
      "Epoch 6/50, Train Loss (Avg): 0.3490, Val RMSE: 0.6793\n",
      "  --> RMSE not improved. (1/10)\n",
      "Epoch 7/50, Train Loss (Avg): 0.3254, Val RMSE: 0.6871\n",
      "  --> RMSE not improved. (2/10)\n",
      "Epoch 8/50, Train Loss (Avg): 0.3019, Val RMSE: 0.6917\n",
      "  --> RMSE not improved. (3/10)\n",
      "Epoch 9/50, Train Loss (Avg): 0.2766, Val RMSE: 0.7025\n",
      "  --> RMSE not improved. (4/10)\n",
      "Epoch 10/50, Train Loss (Avg): 0.2523, Val RMSE: 0.7132\n",
      "  --> RMSE not improved. (5/10)\n",
      "Epoch 11/50, Train Loss (Avg): 0.2277, Val RMSE: 0.7256\n",
      "  --> RMSE not improved. (6/10)\n",
      "Epoch 12/50, Train Loss (Avg): 0.2044, Val RMSE: 0.7318\n",
      "  --> RMSE not improved. (7/10)\n",
      "Epoch 13/50, Train Loss (Avg): 0.1841, Val RMSE: 0.7530\n",
      "  --> RMSE not improved. (8/10)\n",
      "Epoch 14/50, Train Loss (Avg): 0.1668, Val RMSE: 0.7639\n",
      "  --> RMSE not improved. (9/10)\n",
      "Epoch 15/50, Train Loss (Avg): 0.1508, Val RMSE: 0.7643\n",
      "  --> RMSE not improved. (10/10)\n",
      "Early stopping - No validation RMSE improvement for 10 epochs.\n",
      "\n",
      "--- Evaluating Final Model on Test Set ---\n",
      "Loaded best model weights from final_best_aat_rec_model_with_pre_reduced_embedding.pt\n",
      "  Starting test set evaluation...\n",
      "  Test set evaluation completed.\n",
      "\n",
      "--- Performance Evaluation (Final Model with Best Parameters) ---\n",
      "Selected Hyperparameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "Mean Squared Error (MSE): 0.4491\n",
      "Root Mean Squared Error (RMSE): 0.6702\n",
      "Mean Absolute Error (MAE): 0.5238\n",
      "Mean Absolute Percentage Error (MAPE): 18.34%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# --- 1. Utility Functions ---\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return 0.0 # 모든 y_true가 0인 경우 MAPE는 0으로 처리\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "\n",
    "# 첫 번째 파일 로드: sentiment_vector가 포함된 원본 파일\n",
    "# IMPORTANT: Adjust this path to where your JSON file is located on your local machine.\n",
    "print(\"Loading sentiment data from 'review_business_5up_5aspect_3sentiment_vectorized_clean.json'...\")\n",
    "df_sentiment = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "print(f\"Sentiment data loaded. Total records: {len(df_sentiment)}\")\n",
    "\n",
    "# 두 번째 파일 로드: reduced_embedding이 포함된 파일\n",
    "# IMPORTANT: Adjust this path to where your JSONL file is located on your local machine.\n",
    "print(\"Loading reduced embedding data from 'review_business_5up_with_reduced_embedding.jsonl'...\")\n",
    "df_reduced_emb = pd.read_json('review_business_5up_with_reduced_embedding.jsonl', lines=True)\n",
    "print(f\"Reduced embedding data loaded. Total records: {len(df_reduced_emb)}\")\n",
    "\n",
    "# 두 데이터프레임 병합\n",
    "# review_id를 기준으로 병합합니다. review_id가 각 리뷰의 고유 ID라고 가정합니다.\n",
    "# 필요한 컬럼만 선택하여 병합합니다.\n",
    "df_processed = pd.merge(\n",
    "    df_sentiment[['review_id', 'user_id', 'business_id', 'stars', 'sentiment_vector']],\n",
    "    df_reduced_emb[['review_id', 'reduced_embedding']],\n",
    "    on='review_id',\n",
    "    how='inner' # 양쪽에 모두 존재하는 리뷰만 사용\n",
    ")\n",
    "print(f\"Data merged successfully. Total processed records: {len(df_processed)}\")\n",
    "\n",
    "\n",
    "# user_id와 business_id를 연속적인 정수 ID로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "df_processed.loc[:, 'user_encoded'] = user_encoder.fit_transform(df_processed['user_id'])\n",
    "df_processed.loc[:, 'business_encoded'] = business_encoder.fit_transform(df_processed['business_id'])\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "# 데이터 분할\n",
    "# 논문에서 제시된 70/10/20 비율로 데이터 분할\n",
    "train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "val_size_ratio = 1 / 8 # 10% of total data (1/8 of 80%)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42)\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "print(f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\")\n",
    "\n",
    "# 임베딩 차원 설정\n",
    "original_sentiment_dim = len(df_processed['sentiment_vector'].iloc[0]) if not df_processed.empty else 15 # 기존 15차원 감성 벡터\n",
    "loaded_embedding_dim = len(df_processed['reduced_embedding'].iloc[0]) if not df_processed.empty else 32 # 이미 32차원으로 축소된 임베딩\n",
    "\n",
    "# --- 3. PyTorch Dataset and DataLoader Definition ---\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_encoded'].values, dtype=torch.long)\n",
    "        self.business_ids = torch.tensor(df['business_encoded'].values, dtype=torch.long)\n",
    "        self.sentiment_vectors = torch.tensor(np.array(df['sentiment_vector'].tolist()), dtype=torch.float)\n",
    "        # 'reduced_embedding' 컬럼을 사용합니다.\n",
    "        self.embeddings = torch.tensor(np.array(df['reduced_embedding'].tolist()), dtype=torch.float)\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 'embeddings'를 반환 값에 추가합니다. (이미 32차원)\n",
    "        return self.user_ids[idx], self.business_ids[idx], self.sentiment_vectors[idx], \\\n",
    "               self.embeddings[idx], self.stars[idx]\n",
    "\n",
    "# --- 4. Model Architecture Definition ---\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = mlp_dims[-1] if mlp_dims else embedding_dim * 2\n",
    "\n",
    "    def forward(self, user_ids, business_ids):\n",
    "        user_vec = self.user_embedding(user_ids)\n",
    "        business_vec = self.business_embedding(business_ids)\n",
    "        combined_vec = torch.cat((user_vec, business_vec), dim=1)\n",
    "        interaction_features = self.mlp(combined_vec)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectModule(nn.Module):\n",
    "    # 이제 embedding_original_dim, embedding_reduced_dim 대신 loaded_embedding_dim을 받습니다.\n",
    "    def __init__(self, original_sentiment_dim, loaded_embedding_dim, aspect_mlp_dims):\n",
    "        super(ReviewAspectModule, self).__init__()\n",
    "        # 3072 -> 32 차원 축소 MLP는 더 이상 필요 없습니다.\n",
    "        # self.embedding_reducer = nn.Sequential(...) 삭제\n",
    "\n",
    "        layers = []\n",
    "        # MLP의 입력 차원은 원래 감성 벡터 차원 + (이미 줄어든) 임베딩 차원 (15 + 32 = 47)\n",
    "        input_dim = original_sentiment_dim + loaded_embedding_dim\n",
    "        for dim in aspect_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = aspect_mlp_dims[-1] if aspect_mlp_dims else (original_sentiment_dim + loaded_embedding_dim)\n",
    "\n",
    "    def forward(self, sentiment_vectors, embeddings):\n",
    "        # embeddings는 이미 32차원이므로 추가 축소 필요 없음\n",
    "        # reduced_embeddings = self.embedding_reducer(embeddings) 삭제\n",
    "        # 원래 감성 벡터와 (이미 줄어든) 임베딩을 직접 연결\n",
    "        combined_aspect_features = torch.cat((sentiment_vectors, embeddings), dim=1)\n",
    "        aspect_features = self.mlp(combined_aspect_features)\n",
    "        return aspect_features\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, aspect_mlp_dims, final_mlp_dims,\n",
    "                 original_sentiment_dim, loaded_embedding_dim): # 인자 변경\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_interaction_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims\n",
    "        )\n",
    "        self.review_aspect_module = ReviewAspectModule(\n",
    "            original_sentiment_dim, loaded_embedding_dim, aspect_mlp_dims # 변경된 인자 전달\n",
    "        )\n",
    "\n",
    "        final_input_dim = self.customer_restaurant_interaction_module.output_dim + \\\n",
    "                               self.review_aspect_module.output_dim\n",
    "\n",
    "        layers = []\n",
    "        input_dim = final_input_dim\n",
    "        for dim in final_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1)) # Final output is rating (1-dimensional)\n",
    "        self.prediction_mlp = nn.Sequential(*layers)\n",
    "\n",
    "    # forward 함수에 embeddings 인자 추가 (이미 32차원)\n",
    "    def forward(self, user_ids, business_ids, sentiment_vectors, embeddings):\n",
    "        user_biz_features = self.customer_restaurant_interaction_module(user_ids, business_ids)\n",
    "        # review_aspect_module에 두 가지 임베딩 전달 (embeddings는 이미 32차원)\n",
    "        aspect_features = self.review_aspect_module(sentiment_vectors, embeddings)\n",
    "        combined_features = torch.cat((user_biz_features, aspect_features), dim=1)\n",
    "        predicted_rating = self.prediction_mlp(combined_features)\n",
    "        return predicted_rating.squeeze() # Return 1D rating\n",
    "\n",
    "# --- 5. Device Configuration (GPU Setup) ---\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 6. Dataset and DataLoader Creation ---\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df)\n",
    "\n",
    "# --- 7. Apply the Given Best Parameters ---\n",
    "# Previously, these were found via grid search. Now, we explicitly set them.\n",
    "best_params = {\n",
    "    'aspect_mlp_hidden_dims': [64, 32],\n",
    "    'batch_size': 128,\n",
    "    'embedding_dim': 64,\n",
    "    'final_mlp_hidden_dims': [32, 16],\n",
    "    'learning_rate': 0.001,\n",
    "    'user_biz_mlp_hidden_dims': [128, 64]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Applying pre-selected Best Parameters: {best_params}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 8. Final Model Training and Testing (Using Best Parameters) ---\n",
    "final_embedding_dim = best_params['embedding_dim']\n",
    "final_learning_rate = best_params['learning_rate']\n",
    "final_batch_size = best_params['batch_size']\n",
    "final_user_biz_mlp_dims = best_params['user_biz_mlp_hidden_dims']\n",
    "final_aspect_mlp_dims = best_params['aspect_mlp_hidden_dims']\n",
    "final_final_mlp_dims = best_params['final_mlp_hidden_dims']\n",
    "\n",
    "# AATRec 모델 초기화 시 변경된 임베딩 차원 인자 전달\n",
    "final_model = AATRec(num_users, num_businesses, final_embedding_dim,\n",
    "                     final_user_biz_mlp_dims, final_aspect_mlp_dims, final_final_mlp_dims,\n",
    "                     original_sentiment_dim, loaded_embedding_dim).to(device) # loaded_embedding_dim 전달\n",
    "\n",
    "final_criterion = nn.MSELoss()\n",
    "final_optimizer = optim.Adam(final_model.parameters(), lr=final_learning_rate)\n",
    "\n",
    "final_train_loader = DataLoader(train_dataset, batch_size=final_batch_size, shuffle=True)\n",
    "final_val_loader = DataLoader(val_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "final_test_loader = DataLoader(test_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "\n",
    "final_epochs = 50 # Ample epochs for final training\n",
    "final_patience = 10 # More patience for final training\n",
    "final_min_delta = 0.0005 # Stricter improvement criterion\n",
    "\n",
    "best_final_val_rmse = float('inf')\n",
    "epochs_no_improve_final = 0\n",
    "# 모델 저장 경로 변경 (이전 3072차원 처리 모델과 구분)\n",
    "final_model_path = 'final_best_aat_rec_model_with_pre_reduced_embedding.pt'\n",
    "\n",
    "print(\"\\n--- Training Final Model with Best Parameters ---\")\n",
    "for epoch in range(final_epochs):\n",
    "    # Training phase\n",
    "    final_model.train()\n",
    "    total_train_loss = 0\n",
    "    for user_ids, business_ids, sentiment_vectors, embeddings, stars in final_train_loader:\n",
    "        user_ids, business_ids, sentiment_vectors, embeddings, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), \\\n",
    "            embeddings.to(device), stars.to(device) # embeddings는 이미 32차원\n",
    "\n",
    "        final_optimizer.zero_grad()\n",
    "        predictions = final_model(user_ids, business_ids, sentiment_vectors, embeddings)\n",
    "        loss = final_criterion(predictions, stars)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    final_model.eval()\n",
    "    val_predictions = []\n",
    "    val_true_ratings = []\n",
    "    with torch.no_grad():\n",
    "        for user_ids, business_ids, sentiment_vectors, embeddings, stars in final_val_loader:\n",
    "            user_ids, business_ids, sentiment_vectors, embeddings, stars = \\\n",
    "                user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), \\\n",
    "                embeddings.to(device), stars.to(device) # embeddings는 이미 32차원\n",
    "\n",
    "            predictions = final_model(user_ids, business_ids, sentiment_vectors, embeddings)\n",
    "            val_predictions.extend(predictions.cpu().tolist())\n",
    "            val_true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true_ratings, val_predictions))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{final_epochs}, \"\n",
    "          f\"Train Loss (Avg): {total_train_loss / len(final_train_loader):.4f}, \"\n",
    "          f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "    # Early stopping logic for final model\n",
    "    if current_val_rmse < best_final_val_rmse - final_min_delta:\n",
    "        best_final_val_rmse = current_val_rmse\n",
    "        epochs_no_improve_final = 0\n",
    "        torch.save(final_model.state_dict(), final_model_path)\n",
    "        print(f\"  --> RMSE improved. Model saved: {best_final_val_rmse:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve_final += 1\n",
    "        print(f\"  --> RMSE not improved. ({epochs_no_improve_final}/{final_patience})\")\n",
    "        if epochs_no_improve_final == final_patience:\n",
    "            print(f\"Early stopping - No validation RMSE improvement for {final_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "# --- 9. Final Model Testing ---\n",
    "print(\"\\n--- Evaluating Final Model on Test Set ---\")\n",
    "if os.path.exists(final_model_path):\n",
    "    final_model.load_state_dict(torch.load(final_model_path))\n",
    "    print(f\"Loaded best model weights from {final_model_path}\")\n",
    "else:\n",
    "    print(f\"Could not find optimal final model weights at '{final_model_path}'. Testing with current model state.\")\n",
    "\n",
    "final_model.eval()\n",
    "test_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "# 테스트 진행도 출력\n",
    "print(\"  Starting test set evaluation...\")\n",
    "with torch.no_grad():\n",
    "    for user_ids, business_ids, sentiment_vectors, embeddings, stars in final_test_loader:\n",
    "        user_ids, business_ids, sentiment_vectors, embeddings, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), sentiment_vectors.to(device), \\\n",
    "            embeddings.to(device), stars.to(device) # embeddings는 이미 32차원\n",
    "\n",
    "        predictions = final_model(user_ids, business_ids, sentiment_vectors, embeddings)\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "print(\"  Test set evaluation completed.\")\n",
    "\n",
    "mse = mean_squared_error(true_ratings, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "\n",
    "print(f\"\\n--- Performance Evaluation (Final Model with Best Parameters) ---\")\n",
    "print(f\"Selected Hyperparameters: {best_params}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Clean up temporary models directory if it was created by the original script\n",
    "if os.path.exists('temp_models'):\n",
    "    import shutil\n",
    "    shutil.rmtree('temp_models')\n",
    "    print(\"\\nCleaned up 'temp_models' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1342d78-b600-4a3e-bbd3-64ca724a9c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment data from 'review_business_5up_5aspect_3sentiment_vectorized_clean.json' (for review_id only)...\n",
      "Sentiment data loaded. Total records: 447796\n",
      "Loading reduced embedding data from 'review_business_5up_with_reduced_embedding.jsonl'...\n",
      "Reduced embedding data loaded. Total records: 447796\n",
      "Data merged successfully. Total processed records: 447796\n",
      "전체 데이터 수: 447796\n",
      "학습 데이터 수: 313456 (70.00%)\n",
      "검증 데이터 수: 44780 (10.00%)\n",
      "테스트 데이터 수: 89560 (20.00%)\n",
      "Using device: cuda\n",
      "\n",
      "==================================================\n",
      "Applying pre-selected Best Parameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "==================================================\n",
      "\n",
      "--- Training Final Model with Best Parameters (Sentiment Vector Excluded) ---\n",
      "Epoch 1/50, Train Loss (Avg): 1.4664, Val RMSE: 1.0917\n",
      "  --> RMSE improved. Model saved: 1.0917\n",
      "Epoch 2/50, Train Loss (Avg): 0.9607, Val RMSE: 0.9272\n",
      "  --> RMSE improved. Model saved: 0.9272\n",
      "Epoch 3/50, Train Loss (Avg): 0.7682, Val RMSE: 0.8977\n",
      "  --> RMSE improved. Model saved: 0.8977\n",
      "Epoch 4/50, Train Loss (Avg): 0.6945, Val RMSE: 0.8905\n",
      "  --> RMSE improved. Model saved: 0.8905\n",
      "Epoch 5/50, Train Loss (Avg): 0.6402, Val RMSE: 0.8819\n",
      "  --> RMSE improved. Model saved: 0.8819\n",
      "Epoch 6/50, Train Loss (Avg): 0.5950, Val RMSE: 0.8836\n",
      "  --> RMSE not improved. (1/10)\n",
      "Epoch 7/50, Train Loss (Avg): 0.5501, Val RMSE: 0.8780\n",
      "  --> RMSE improved. Model saved: 0.8780\n",
      "Epoch 8/50, Train Loss (Avg): 0.5040, Val RMSE: 0.8698\n",
      "  --> RMSE improved. Model saved: 0.8698\n",
      "Epoch 9/50, Train Loss (Avg): 0.4625, Val RMSE: 0.8826\n",
      "  --> RMSE not improved. (1/10)\n",
      "Epoch 10/50, Train Loss (Avg): 0.4174, Val RMSE: 0.8794\n",
      "  --> RMSE not improved. (2/10)\n",
      "Epoch 11/50, Train Loss (Avg): 0.3808, Val RMSE: 0.8839\n",
      "  --> RMSE not improved. (3/10)\n",
      "Epoch 12/50, Train Loss (Avg): 0.3436, Val RMSE: 0.8926\n",
      "  --> RMSE not improved. (4/10)\n",
      "Epoch 13/50, Train Loss (Avg): 0.3118, Val RMSE: 0.9205\n",
      "  --> RMSE not improved. (5/10)\n",
      "Epoch 14/50, Train Loss (Avg): 0.2829, Val RMSE: 0.9134\n",
      "  --> RMSE not improved. (6/10)\n",
      "Epoch 15/50, Train Loss (Avg): 0.2570, Val RMSE: 0.9473\n",
      "  --> RMSE not improved. (7/10)\n",
      "Epoch 16/50, Train Loss (Avg): 0.2327, Val RMSE: 0.9180\n",
      "  --> RMSE not improved. (8/10)\n",
      "Epoch 17/50, Train Loss (Avg): 0.2125, Val RMSE: 0.9306\n",
      "  --> RMSE not improved. (9/10)\n",
      "Epoch 18/50, Train Loss (Avg): 0.1958, Val RMSE: 0.9352\n",
      "  --> RMSE not improved. (10/10)\n",
      "Early stopping - No validation RMSE improvement for 10 epochs.\n",
      "\n",
      "--- Evaluating Final Model on Test Set (Sentiment Vector Excluded) ---\n",
      "Loaded best model weights from final_best_aat_rec_model_no_sentiment.pt\n",
      "  Starting test set evaluation...\n",
      "  Test set evaluation completed.\n",
      "\n",
      "--- Performance Evaluation (Final Model with Best Parameters, Sentiment Vector Excluded) ---\n",
      "Selected Hyperparameters: {'aspect_mlp_hidden_dims': [64, 32], 'batch_size': 128, 'embedding_dim': 64, 'final_mlp_hidden_dims': [32, 16], 'learning_rate': 0.001, 'user_biz_mlp_hidden_dims': [128, 64]}\n",
      "Mean Squared Error (MSE): 0.7450\n",
      "Root Mean Squared Error (RMSE): 0.8631\n",
      "Mean Absolute Error (MAE): 0.6709\n",
      "Mean Absolute Percentage Error (MAPE): 25.31%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "\n",
    "# --- 1. Utility Functions ---\n",
    "\n",
    "# MAPE를 위한 유틸리티 함수 (0으로 나누는 오류 방지)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    non_zero_true = y_true != 0\n",
    "    if np.sum(non_zero_true) == 0:\n",
    "        return 0.0 # 모든 y_true가 0인 경우 MAPE는 0으로 처리\n",
    "    return np.mean(np.abs((y_true[non_zero_true] - y_pred[non_zero_true]) / y_true[non_zero_true])) * 100\n",
    "\n",
    "# --- 2. Data Loading and Preprocessing ---\n",
    "\n",
    "# 첫 번째 파일 로드: sentiment_vector가 포함된 원본 파일 (이번에는 사용하지 않음)\n",
    "# IMPORTANT: Adjust this path to where your JSON file is located on your local machine.\n",
    "print(\"Loading sentiment data from 'review_business_5up_5aspect_3sentiment_vectorized_clean.json' (for review_id only)...\")\n",
    "df_sentiment = pd.read_json('review_business_5up_5aspect_3sentiment_vectorized_clean.json', lines=True)\n",
    "print(f\"Sentiment data loaded. Total records: {len(df_sentiment)}\")\n",
    "\n",
    "# 두 번째 파일 로드: reduced_embedding이 포함된 파일\n",
    "# IMPORTANT: Adjust this path to where your JSONL file is located on your local machine.\n",
    "print(\"Loading reduced embedding data from 'review_business_5up_with_reduced_embedding.jsonl'...\")\n",
    "df_reduced_emb = pd.read_json('review_business_5up_with_reduced_embedding.jsonl', lines=True)\n",
    "print(f\"Reduced embedding data loaded. Total records: {len(df_reduced_emb)}\")\n",
    "\n",
    "# 두 데이터프레임 병합\n",
    "# review_id를 기준으로 병합합니다. review_id가 각 리뷰의 고유 ID라고 가정합니다.\n",
    "# sentiment_vector 컬럼을 제외하고 병합합니다.\n",
    "df_processed = pd.merge(\n",
    "    df_sentiment[['review_id', 'user_id', 'business_id', 'stars']], # sentiment_vector 제외\n",
    "    df_reduced_emb[['review_id', 'reduced_embedding']],\n",
    "    on='review_id',\n",
    "    how='inner' # 양쪽에 모두 존재하는 리뷰만 사용\n",
    ")\n",
    "print(f\"Data merged successfully. Total processed records: {len(df_processed)}\")\n",
    "\n",
    "# user_id와 business_id를 연속적인 정수 ID로 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "df_processed.loc[:, 'user_encoded'] = user_encoder.fit_transform(df_processed['user_id'])\n",
    "df_processed.loc[:, 'business_encoded'] = business_encoder.fit_transform(df_processed['business_id'])\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "# 데이터 분할\n",
    "# 논문에서 제시된 70/10/20 비율로 데이터 분할\n",
    "train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "val_size_ratio = 1 / 8 # 10% of total data (1/8 of 80%)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42)\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "print(f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\")\n",
    "\n",
    "# 임베딩 차원 설정\n",
    "# original_sentiment_dim은 이제 사용되지 않습니다.\n",
    "loaded_embedding_dim = len(df_processed['reduced_embedding'].iloc[0]) if not df_processed.empty else 32 # 이미 32차원으로 축소된 임베딩\n",
    "\n",
    "# --- 3. PyTorch Dataset and DataLoader Definition ---\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.user_ids = torch.tensor(df['user_encoded'].values, dtype=torch.long)\n",
    "        self.business_ids = torch.tensor(df['business_encoded'].values, dtype=torch.long)\n",
    "        # sentiment_vectors는 이제 포함되지 않습니다.\n",
    "        self.embeddings = torch.tensor(np.array(df['reduced_embedding'].tolist()), dtype=torch.float)\n",
    "        self.stars = torch.tensor(df['stars'].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stars)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # sentiment_vectors를 제거하고 embeddings만 반환합니다.\n",
    "        return self.user_ids[idx], self.business_ids[idx], self.embeddings[idx], self.stars[idx]\n",
    "\n",
    "# --- 4. Model Architecture Definition ---\n",
    "class CustomerRestaurantInteractionModule(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim, mlp_dims):\n",
    "        super(CustomerRestaurantInteractionModule, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.business_embedding = nn.Embedding(num_businesses, embedding_dim)\n",
    "\n",
    "        layers = []\n",
    "        input_dim = embedding_dim * 2\n",
    "        for dim in mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = mlp_dims[-1] if mlp_dims else embedding_dim * 2\n",
    "\n",
    "    def forward(self, user_ids, business_ids):\n",
    "        user_vec = self.user_embedding(user_ids)\n",
    "        business_vec = self.business_embedding(business_ids)\n",
    "        combined_vec = torch.cat((user_vec, business_vec), dim=1)\n",
    "        interaction_features = self.mlp(combined_vec)\n",
    "        return interaction_features\n",
    "\n",
    "class ReviewAspectModule(nn.Module):\n",
    "    # original_sentiment_dim을 더 이상 받지 않습니다.\n",
    "    def __init__(self, loaded_embedding_dim, aspect_mlp_dims):\n",
    "        super(ReviewAspectModule, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        # MLP의 입력 차원은 이제 오직 loaded_embedding_dim입니다.\n",
    "        input_dim = loaded_embedding_dim\n",
    "        for dim in aspect_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        self.output_dim = aspect_mlp_dims[-1] if aspect_mlp_dims else loaded_embedding_dim\n",
    "\n",
    "    # forward 함수에서 sentiment_vectors 인자 제거\n",
    "    def forward(self, embeddings):\n",
    "        # embeddings는 이미 32차원이므로 추가 축소 필요 없음\n",
    "        # combined_aspect_features는 이제 embeddings 자체입니다.\n",
    "        aspect_features = self.mlp(embeddings)\n",
    "        return aspect_features\n",
    "\n",
    "class AATRec(nn.Module):\n",
    "    def __init__(self, num_users, num_businesses, embedding_dim,\n",
    "                 user_biz_mlp_dims, aspect_mlp_dims, final_mlp_dims,\n",
    "                 loaded_embedding_dim): # original_sentiment_dim 제거\n",
    "        super(AATRec, self).__init__()\n",
    "        self.customer_restaurant_interaction_module = CustomerRestaurantInteractionModule(\n",
    "            num_users, num_businesses, embedding_dim, user_biz_mlp_dims\n",
    "        )\n",
    "        self.review_aspect_module = ReviewAspectModule(\n",
    "            loaded_embedding_dim, aspect_mlp_dims # 변경된 인자 전달\n",
    "        )\n",
    "\n",
    "        final_input_dim = self.customer_restaurant_interaction_module.output_dim + \\\n",
    "                               self.review_aspect_module.output_dim\n",
    "\n",
    "        layers = []\n",
    "        input_dim = final_input_dim\n",
    "        for dim in final_mlp_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = dim\n",
    "        layers.append(nn.Linear(input_dim, 1)) # Final output is rating (1-dimensional)\n",
    "        self.prediction_mlp = nn.Sequential(*layers)\n",
    "\n",
    "    # forward 함수에서 sentiment_vectors 인자 제거\n",
    "    def forward(self, user_ids, business_ids, embeddings):\n",
    "        user_biz_features = self.customer_restaurant_interaction_module(user_ids, business_ids)\n",
    "        # review_aspect_module에 embeddings만 전달\n",
    "        aspect_features = self.review_aspect_module(embeddings)\n",
    "        combined_features = torch.cat((user_biz_features, aspect_features), dim=1)\n",
    "        predicted_rating = self.prediction_mlp(combined_features)\n",
    "        return predicted_rating.squeeze() # Return 1D rating\n",
    "\n",
    "# --- 5. Device Configuration (GPU Setup) ---\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 6. Dataset and DataLoader Creation ---\n",
    "train_dataset = ReviewDataset(train_df)\n",
    "val_dataset = ReviewDataset(val_df)\n",
    "test_dataset = ReviewDataset(test_df)\n",
    "\n",
    "# --- 7. Apply the Given Best Parameters ---\n",
    "# Previously, these were found via grid search. Now, we explicitly set them.\n",
    "best_params = {\n",
    "    'aspect_mlp_hidden_dims': [64, 32],\n",
    "    'batch_size': 128,\n",
    "    'embedding_dim': 64,\n",
    "    'final_mlp_hidden_dims': [32, 16],\n",
    "    'learning_rate': 0.001,\n",
    "    'user_biz_mlp_hidden_dims': [128, 64]\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Applying pre-selected Best Parameters: {best_params}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# --- 8. Final Model Training and Testing (Using Best Parameters) ---\n",
    "final_embedding_dim = best_params['embedding_dim']\n",
    "final_learning_rate = best_params['learning_rate']\n",
    "final_batch_size = best_params['batch_size']\n",
    "final_user_biz_mlp_dims = best_params['user_biz_mlp_hidden_dims']\n",
    "final_aspect_mlp_dims = best_params['aspect_mlp_hidden_dims']\n",
    "final_final_mlp_dims = best_params['final_mlp_hidden_dims']\n",
    "\n",
    "# AATRec 모델 초기화 시 변경된 임베딩 차원 인자 전달\n",
    "final_model = AATRec(num_users, num_businesses, final_embedding_dim,\n",
    "                     final_user_biz_mlp_dims, final_aspect_mlp_dims, final_final_mlp_dims,\n",
    "                     loaded_embedding_dim).to(device) # original_sentiment_dim 제거\n",
    "\n",
    "final_criterion = nn.MSELoss()\n",
    "final_optimizer = optim.Adam(final_model.parameters(), lr=final_learning_rate)\n",
    "\n",
    "final_train_loader = DataLoader(train_dataset, batch_size=final_batch_size, shuffle=True)\n",
    "final_val_loader = DataLoader(val_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "final_test_loader = DataLoader(test_dataset, batch_size=final_batch_size, shuffle=False)\n",
    "\n",
    "final_epochs = 50 # Ample epochs for final training\n",
    "final_patience = 10 # More patience for final training\n",
    "final_min_delta = 0.0005 # Stricter improvement criterion\n",
    "\n",
    "best_final_val_rmse = float('inf')\n",
    "epochs_no_improve_final = 0\n",
    "# 모델 저장 경로 변경 (sentiment vector가 제외된 모델임을 명시)\n",
    "final_model_path = 'final_best_aat_rec_model_no_sentiment.pt'\n",
    "\n",
    "print(\"\\n--- Training Final Model with Best Parameters (Sentiment Vector Excluded) ---\")\n",
    "for epoch in range(final_epochs):\n",
    "    # Training phase\n",
    "    final_model.train()\n",
    "    total_train_loss = 0\n",
    "    # DataLoader에서 sentiment_vectors 인자 제거\n",
    "    for user_ids, business_ids, embeddings, stars in final_train_loader:\n",
    "        user_ids, business_ids, embeddings, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), \\\n",
    "            embeddings.to(device), stars.to(device) # embeddings는 이미 32차원\n",
    "\n",
    "        final_optimizer.zero_grad()\n",
    "        # forward 함수에 sentiment_vectors 인자 제거\n",
    "        predictions = final_model(user_ids, business_ids, embeddings)\n",
    "        loss = final_criterion(predictions, stars)\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation phase\n",
    "    final_model.eval()\n",
    "    val_predictions = []\n",
    "    val_true_ratings = []\n",
    "    with torch.no_grad():\n",
    "        # DataLoader에서 sentiment_vectors 인자 제거\n",
    "        for user_ids, business_ids, embeddings, stars in final_val_loader:\n",
    "            user_ids, business_ids, embeddings, stars = \\\n",
    "                user_ids.to(device), business_ids.to(device), \\\n",
    "                embeddings.to(device), stars.to(device) # embeddings는 이미 32차원\n",
    "\n",
    "            # forward 함수에 sentiment_vectors 인자 제거\n",
    "            predictions = final_model(user_ids, business_ids, embeddings)\n",
    "            val_predictions.extend(predictions.cpu().tolist())\n",
    "            val_true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "    current_val_rmse = np.sqrt(mean_squared_error(val_true_ratings, val_predictions))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{final_epochs}, \"\n",
    "          f\"Train Loss (Avg): {total_train_loss / len(final_train_loader):.4f}, \"\n",
    "          f\"Val RMSE: {current_val_rmse:.4f}\")\n",
    "\n",
    "    # Early stopping logic for final model\n",
    "    if current_val_rmse < best_final_val_rmse - final_min_delta:\n",
    "        best_final_val_rmse = current_val_rmse\n",
    "        epochs_no_improve_final = 0\n",
    "        torch.save(final_model.state_dict(), final_model_path)\n",
    "        print(f\"  --> RMSE improved. Model saved: {best_final_val_rmse:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve_final += 1\n",
    "        print(f\"  --> RMSE not improved. ({epochs_no_improve_final}/{final_patience})\")\n",
    "        if epochs_no_improve_final == final_patience:\n",
    "            print(f\"Early stopping - No validation RMSE improvement for {final_patience} epochs.\")\n",
    "            break\n",
    "\n",
    "# --- 9. Final Model Testing ---\n",
    "print(\"\\n--- Evaluating Final Model on Test Set (Sentiment Vector Excluded) ---\")\n",
    "if os.path.exists(final_model_path):\n",
    "    final_model.load_state_dict(torch.load(final_model_path))\n",
    "    print(f\"Loaded best model weights from {final_model_path}\")\n",
    "else:\n",
    "    print(f\"Could not find optimal final model weights at '{final_model_path}'. Testing with current model state.\")\n",
    "\n",
    "final_model.eval()\n",
    "test_predictions = []\n",
    "true_ratings = []\n",
    "\n",
    "# 테스트 진행도 출력\n",
    "print(\"  Starting test set evaluation...\")\n",
    "with torch.no_grad():\n",
    "    # DataLoader에서 sentiment_vectors 인자 제거\n",
    "    for user_ids, business_ids, embeddings, stars in final_test_loader:\n",
    "        user_ids, business_ids, embeddings, stars = \\\n",
    "            user_ids.to(device), business_ids.to(device), \\\n",
    "            embeddings.to(device), stars.to(device) # embeddings는 이미 32차원\n",
    "\n",
    "        # forward 함수에 sentiment_vectors 인자 제거\n",
    "        predictions = final_model(user_ids, business_ids, embeddings)\n",
    "        test_predictions.extend(predictions.cpu().tolist())\n",
    "        true_ratings.extend(stars.cpu().tolist())\n",
    "\n",
    "print(\"  Test set evaluation completed.\")\n",
    "\n",
    "mse = mean_squared_error(true_ratings, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "\n",
    "print(f\"\\n--- Performance Evaluation (Final Model with Best Parameters, Sentiment Vector Excluded) ---\")\n",
    "print(f\"Selected Hyperparameters: {best_params}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Clean up temporary models directory if it was created by the original script\n",
    "if os.path.exists('temp_models'):\n",
    "    import shutil\n",
    "    shutil.rmtree('temp_models')\n",
    "    print(\"\\nCleaned up 'temp_models' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b3512-937a-432b-a354-39f8b9762eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
