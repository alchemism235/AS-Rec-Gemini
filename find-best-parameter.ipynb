{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcdfef01-9d6e-4004-9320-e85e4f59825a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 완료\n",
      "전체 데이터 수: 447796\n",
      "학습 데이터 수: 313456 (70.00%)\n",
      "검증 데이터 수: 44780 (10.00%)\n",
      "테스트 데이터 수: 89560 (20.00%)\n",
      "제미니 임베딩 차원: 3072\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import random\n",
    "\n",
    "# 파라미터 (최종 저장 경로 설정)\n",
    "PARQUET_PATH = 'review_data_optimized.parquet'\n",
    "MODEL_SAVE_PATH = 'final_best_hybrid_gemini_model.keras'\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_parquet(PARQUET_PATH)\n",
    "print(\"데이터 로드 완료\")\n",
    "\n",
    "# 데이터 분할 및 전처리\n",
    "df_processed = df[['user_id', 'business_id', 'stars', 'embedding']].copy()\n",
    "\n",
    "# 데이터 7:1:2로 분할\n",
    "train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "val_size_ratio = 1 / 8  # 전체 데이터의 10%\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42)\n",
    "\n",
    "# LabelEncoder를 사용하여 사용자 ID와 비즈니스 ID 인코딩\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "train_df.loc[:, 'user_encoded'] = user_encoder.fit_transform(train_df['user_id'])\n",
    "train_df.loc[:, 'business_encoded'] = business_encoder.fit_transform(train_df['business_id'])\n",
    "\n",
    "user_mapping = {label: i for i, label in enumerate(user_encoder.classes_)}\n",
    "business_mapping = {label: i for i, label in enumerate(business_encoder.classes_)}\n",
    "\n",
    "val_df.loc[:, 'user_encoded'] = val_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "val_df.loc[:, 'business_encoded'] = val_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "test_df.loc[:, 'user_encoded'] = test_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "test_df.loc[:, 'business_encoded'] = test_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "print(f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\")\n",
    "\n",
    "train_embeddings = np.array(train_df['embedding'].tolist())\n",
    "val_embeddings = np.array(val_df['embedding'].tolist())\n",
    "test_embeddings = np.array(test_df['embedding'].tolist())\n",
    "\n",
    "gemini_embedding_dim = len(train_df['embedding'].iloc[0]) if not train_df.empty else 3072\n",
    "print(f\"제미니 임베딩 차원: {gemini_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b237b157-9302-4e53-acd8-eafcd19786da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_gemini_model(num_users, num_businesses, user_embedding_dim, business_embedding_dim,\n",
    "                             gemini_embedding_dim, user_biz_mlp_dims, gemini_mlp_dims, final_mlp_dims):\n",
    "    \n",
    "    # 사용자-비즈니스 상호작용 모듈\n",
    "    user_input = keras.Input(shape=(1,), name='user_id')\n",
    "    business_input = keras.Input(shape=(1,), name='business_id')\n",
    "    user_embedding = layers.Embedding(num_users, user_embedding_dim, name='user_embedding')(user_input)\n",
    "    user_vec = layers.Flatten()(user_embedding)\n",
    "    business_embedding = layers.Embedding(num_businesses, business_embedding_dim, name='business_embedding')(business_input)\n",
    "    business_vec = layers.Flatten()(business_embedding)\n",
    "    combined_vec = layers.concatenate([user_vec, business_vec], axis=1)\n",
    "    interaction_features = combined_vec\n",
    "    for dim in user_biz_mlp_dims:\n",
    "        interaction_features = layers.Dense(dim, activation='relu')(interaction_features)\n",
    "\n",
    "    # 제미니 임베딩 모듈\n",
    "    gemini_input = keras.Input(shape=(gemini_embedding_dim,), name='gemini_embedding')\n",
    "    gemini_features = gemini_input\n",
    "    for dim in gemini_mlp_dims:\n",
    "        gemini_features = layers.Dense(dim, activation='relu')(gemini_features)\n",
    "    \n",
    "    # 최종 예측 모듈\n",
    "    final_combined_features = layers.concatenate([interaction_features, gemini_features], axis=1)\n",
    "    predicted_rating = final_combined_features\n",
    "    for dim in final_mlp_dims:\n",
    "        predicted_rating = layers.Dense(dim, activation='relu')(predicted_rating)\n",
    "    predicted_rating = layers.Dense(1, activation='linear', name='output_rating')(predicted_rating)\n",
    "    \n",
    "    model = models.Model(inputs=[user_input, business_input, gemini_input], outputs=predicted_rating)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db742842-1201-4f04-968b-1c5ebc90194c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "랜덤 서치를 통해 최적 하이퍼파라미터를 찾습니다. (탐색 횟수: 10)\n",
      "==================================================\n",
      "\n",
      "--- 랜덤 서치 1/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 128, 'business_embedding_dim': 64, 'gemini_mlp_dims': [1536, 768, 384, 192], 'user_biz_mlp_dims': [64, 32], 'final_mlp_dims': [128, 64], 'learning_rate': 0.005, 'batch_size': 256}\n",
      " -> 검증 RMSE: 0.4755\n",
      " -> 최적 모델 업데이트!\n",
      "\n",
      "--- 랜덤 서치 2/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 32, 'business_embedding_dim': 128, 'gemini_mlp_dims': [1536, 768], 'user_biz_mlp_dims': [128, 64], 'final_mlp_dims': [128, 64], 'learning_rate': 0.005, 'batch_size': 256}\n",
      " -> 검증 RMSE: 0.4769\n",
      "\n",
      "--- 랜덤 서치 3/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 64, 'business_embedding_dim': 32, 'gemini_mlp_dims': [1536, 768], 'user_biz_mlp_dims': [256, 128], 'final_mlp_dims': [256, 128], 'learning_rate': 0.0001, 'batch_size': 256}\n",
      " -> 검증 RMSE: 0.4707\n",
      " -> 최적 모델 업데이트!\n",
      "\n",
      "--- 랜덤 서치 4/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 128, 'business_embedding_dim': 128, 'gemini_mlp_dims': [1536, 768, 384, 192], 'user_biz_mlp_dims': [64, 32], 'final_mlp_dims': [128, 64], 'learning_rate': 0.005, 'batch_size': 64}\n",
      " -> 검증 RMSE: 0.4751\n",
      "\n",
      "--- 랜덤 서치 5/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 128, 'business_embedding_dim': 32, 'gemini_mlp_dims': [1536, 768, 384, 192], 'user_biz_mlp_dims': [128, 64], 'final_mlp_dims': [64, 32], 'learning_rate': 0.0001, 'batch_size': 256}\n",
      " -> 검증 RMSE: 0.4687\n",
      " -> 최적 모델 업데이트!\n",
      "\n",
      "--- 랜덤 서치 6/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 128, 'business_embedding_dim': 32, 'gemini_mlp_dims': [1536, 768], 'user_biz_mlp_dims': [128, 64], 'final_mlp_dims': [256, 128], 'learning_rate': 0.005, 'batch_size': 64}\n",
      " -> 검증 RMSE: 0.4750\n",
      "\n",
      "--- 랜덤 서치 7/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 32, 'business_embedding_dim': 128, 'gemini_mlp_dims': [1536, 768], 'user_biz_mlp_dims': [64, 32], 'final_mlp_dims': [128, 64], 'learning_rate': 0.0005, 'batch_size': 64}\n",
      " -> 검증 RMSE: 0.4783\n",
      "\n",
      "--- 랜덤 서치 8/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 32, 'business_embedding_dim': 128, 'gemini_mlp_dims': [1536, 768, 384, 192], 'user_biz_mlp_dims': [256, 128], 'final_mlp_dims': [128, 64], 'learning_rate': 0.005, 'batch_size': 64}\n",
      " -> 검증 RMSE: 0.4719\n",
      "\n",
      "--- 랜덤 서치 9/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 32, 'business_embedding_dim': 32, 'gemini_mlp_dims': [1536, 768], 'user_biz_mlp_dims': [256, 128], 'final_mlp_dims': [256, 128], 'learning_rate': 0.0005, 'batch_size': 256}\n",
      " -> 검증 RMSE: 0.4734\n",
      "\n",
      "--- 랜덤 서치 10/10 시작 ---\n",
      "샘플링된 파라미터: {'user_embedding_dim': 32, 'business_embedding_dim': 64, 'gemini_mlp_dims': [1536, 768], 'user_biz_mlp_dims': [64, 32], 'final_mlp_dims': [128, 64], 'learning_rate': 0.001, 'batch_size': 128}\n",
      " -> 검증 RMSE: 0.4858\n",
      "\n",
      "==================================================\n",
      "최종 최적 파라미터: {'user_embedding_dim': 128, 'business_embedding_dim': 32, 'gemini_mlp_dims': [1536, 768, 384, 192], 'user_biz_mlp_dims': [128, 64], 'final_mlp_dims': [64, 32], 'learning_rate': 0.0001, 'batch_size': 256}\n",
      "최소 검증 RMSE: 0.4687\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# --- 최적 파라미터 탐색 공간 정의 ---\n",
    "param_distributions = {\n",
    "    'user_embedding_dim': [32, 64, 128],\n",
    "    'business_embedding_dim': [32, 64, 128],\n",
    "    'gemini_mlp_dims': [\n",
    "        [1536, 768],\n",
    "        [1536, 768, 384],\n",
    "        [1536, 768, 384, 192]\n",
    "    ],\n",
    "    'user_biz_mlp_dims': [\n",
    "        [64, 32],\n",
    "        [128, 64],\n",
    "        [256, 128]\n",
    "    ],\n",
    "    'final_mlp_dims': [\n",
    "        [64, 32],\n",
    "        [128, 64],\n",
    "        [256, 128]\n",
    "    ],\n",
    "    'learning_rate': [0.01, 0.005, 0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [64, 128, 256]\n",
    "}\n",
    "\n",
    "# --- 랜덤 서치 실행 설정 ---\n",
    "num_searches = 10 \n",
    "\n",
    "best_val_rmse = float('inf')\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# --- 랜덤 서치 루프 ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"랜덤 서치를 통해 최적 하이퍼파라미터를 찾습니다. (탐색 횟수: {num_searches})\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i in range(num_searches):\n",
    "    print(f\"\\n--- 랜덤 서치 {i+1}/{num_searches} 시작 ---\")\n",
    "\n",
    "    # 하이퍼파라미터 무작위 샘플링\n",
    "    current_params = {key: random.choice(values) for key, values in param_distributions.items()}\n",
    "    print(f\"샘플링된 파라미터: {current_params}\")\n",
    "    \n",
    "    # 모델 구축 및 컴파일\n",
    "    model = build_hybrid_gemini_model(\n",
    "        num_users, num_businesses,\n",
    "        current_params['user_embedding_dim'], current_params['business_embedding_dim'],\n",
    "        gemini_embedding_dim,\n",
    "        current_params['user_biz_mlp_dims'], current_params['gemini_mlp_dims'],\n",
    "        current_params['final_mlp_dims'])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=current_params['learning_rate']),\n",
    "                    loss='mse',\n",
    "                    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mae'])\n",
    "    \n",
    "    # EarlyStopping 콜백\n",
    "    early_stopping_callback = callbacks.EarlyStopping(\n",
    "        monitor='val_rmse', patience=5, min_delta=0.0005, mode='min', restore_best_weights=True)\n",
    "        \n",
    "    # 모델 학습 (verbose=0으로 설정하여 출력 간소화)\n",
    "    history = model.fit(\n",
    "        {'user_id': train_df['user_encoded'],\n",
    "         'business_id': train_df['business_encoded'],\n",
    "         'gemini_embedding': train_embeddings},\n",
    "        train_df['stars'],\n",
    "        batch_size=current_params['batch_size'],\n",
    "        epochs=50,\n",
    "        validation_data=(\n",
    "            {'user_id': val_df['user_encoded'],\n",
    "             'business_id': val_df['business_encoded'],\n",
    "             'gemini_embedding': val_embeddings},\n",
    "            val_df['stars']\n",
    "        ),\n",
    "        callbacks=[early_stopping_callback],\n",
    "        verbose=0)\n",
    "\n",
    "    current_val_rmse = min(history.history['val_rmse'])\n",
    "    print(f\" -> 검증 RMSE: {current_val_rmse:.4f}\")\n",
    "    \n",
    "    # 최적 파라미터 업데이트\n",
    "    if current_val_rmse < best_val_rmse:\n",
    "        best_val_rmse = current_val_rmse\n",
    "        best_params = current_params\n",
    "        best_model = model\n",
    "        print(\" -> 최적 모델 업데이트!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"최종 최적 파라미터: {best_params}\")\n",
    "print(f\"최소 검증 RMSE: {best_val_rmse:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42342775-424f-4cbd-83fb-4009f65ceb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 모델이 final_best_hybrid_gemini_model.keras에 저장되었습니다.\n",
      "\n",
      "==================================================\n",
      "모델 평가 시작\n",
      "==================================================\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "최적 파라미터: {'user_embedding_dim': 128, 'business_embedding_dim': 32, 'gemini_mlp_dims': [1536, 768, 384, 192], 'user_biz_mlp_dims': [128, 64], 'final_mlp_dims': [64, 32], 'learning_rate': 0.0001, 'batch_size': 256}\n",
      "Mean Squared Error (MSE): 0.2182\n",
      "Root Mean Squared Error (RMSE): 0.4671\n",
      "Mean Absolute Error (MAE): 0.3547\n",
      "Mean Absolute Percentage Error (MAPE): 0.1143\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델 저장 및 최종 평가\n",
    "if best_model:\n",
    "    best_model.save(MODEL_SAVE_PATH)\n",
    "    print(f\"최적 모델이 {MODEL_SAVE_PATH}에 저장되었습니다.\")\n",
    "    final_model = best_model\n",
    "else:\n",
    "    print(f\"최적 모델을 찾을 수 없습니다. 기본 모델을 로드합니다.\")\n",
    "    # 랜덤 서치가 실패했을 경우 대비 (일반적으로 발생하지 않음)\n",
    "    final_model = keras.models.load_model(MODEL_SAVE_PATH)\n",
    "\n",
    "# --- 모델 평가 ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"모델 평가 시작\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_predictions = final_model.predict(\n",
    "    {'user_id': test_df['user_encoded'],\n",
    "     'business_id': test_df['business_encoded'],\n",
    "     'gemini_embedding': test_embeddings}).flatten()\n",
    "\n",
    "true_ratings = test_df['stars'].values\n",
    "mse = mean_squared_error(true_ratings, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "\n",
    "print(f\"최적 파라미터: {best_params}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
