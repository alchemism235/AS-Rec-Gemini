{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a914c52a-4cfb-4113-908e-2118452e8ba7",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b38ca08-2950-45f2-aba9-bbcb59c0065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d9c16-4e3c-43a6-87a7-bb1e76d56f0e",
   "metadata": {},
   "source": [
    "파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c48a4fb-12c8-40c3-bb21-4397658a417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 데이터 로드\n"
     ]
    }
   ],
   "source": [
    "PARQUET_PATH = 'review_data_optimized_fl.parquet'\n",
    "MODEL_SAVE_PATH = 'final_best_hybrid_gemini_model_fl.keras'\n",
    "\n",
    "best_params = {\n",
    "    'user_embedding_dim': 128,\n",
    "    'business_embedding_dim': 32,\n",
    "    'gemini_mlp_dims': [1536, 768, 384, 192],\n",
    "    'user_biz_mlp_dims': [128, 64],\n",
    "    'final_mlp_dims': [64, 32],\n",
    "    'learning_rate': 0.0001,\n",
    "    'batch_size': 256\n",
    "}\n",
    "\n",
    "df = pd.read_parquet(PARQUET_PATH)\n",
    "print(\" 데이터 로드\")\n",
    "df_processed = df[['user_id', 'business_id', 'review_stars', 'embedding']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be44d46-947c-420c-89ca-7c0a94d8c496",
   "metadata": {},
   "source": [
    "모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8372b8f6-7b5c-4fd9-bb55-fc7aae873b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_gemini_model(num_users, num_businesses, user_embedding_dim, business_embedding_dim,\n",
    "                              gemini_embedding_dim, user_biz_mlp_dims, gemini_mlp_dims, final_mlp_dims):\n",
    "    \n",
    "    # 사용자-비즈니스 상호작용 모듈\n",
    "    user_input = keras.Input(shape=(1,), name='user_id')\n",
    "    business_input = keras.Input(shape=(1,), name='business_id')\n",
    "\n",
    "    user_embedding = layers.Embedding(num_users, user_embedding_dim, name='user_embedding')(user_input)\n",
    "    user_vec = layers.Flatten()(user_embedding)\n",
    "\n",
    "    business_embedding = layers.Embedding(num_businesses, business_embedding_dim, name='business_embedding')(business_input)\n",
    "    business_vec = layers.Flatten()(business_embedding)\n",
    "\n",
    "    combined_vec = layers.concatenate([user_vec, business_vec], axis=1)\n",
    "    interaction_features = combined_vec\n",
    "    for dim in user_biz_mlp_dims:\n",
    "        interaction_features = layers.Dense(dim, activation='relu')(interaction_features)\n",
    "\n",
    "    # Gemini 임베딩 모듈\n",
    "    gemini_input = keras.Input(shape=(gemini_embedding_dim,), name='gemini_embedding')\n",
    "    gemini_features = gemini_input\n",
    "    for dim in gemini_mlp_dims:\n",
    "        gemini_features = layers.Dense(dim, activation='relu')(gemini_features)\n",
    "    \n",
    "    # 최종 예측 모듈\n",
    "    final_combined_features = layers.concatenate([interaction_features, gemini_features], axis=1)\n",
    "\n",
    "    predicted_rating = final_combined_features\n",
    "    for dim in final_mlp_dims:\n",
    "        predicted_rating = layers.Dense(dim, activation='relu')(predicted_rating)\n",
    "    predicted_rating = layers.Dense(1, activation='linear', name='output_rating')(predicted_rating)\n",
    "    \n",
    "    model = models.Model(inputs=[user_input, business_input, gemini_input],\n",
    "                         outputs=predicted_rating)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce5f55-f715-4ac8-8208-975a0b54513a",
   "metadata": {},
   "source": [
    "데이터 분할 / 5회 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78df1c1f-75a0-4f97-96d8-828787a3478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alche\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "1번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 26ms/step - loss: 1.7357 - mae: 0.7547 - rmse: 1.1619 - val_loss: 0.2292 - val_mae: 0.3636 - val_rmse: 0.4788\n",
      "Epoch 2/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.2135 - mae: 0.3471 - rmse: 0.4621 - val_loss: 0.2164 - val_mae: 0.3507 - val_rmse: 0.4652\n",
      "Epoch 3/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1893 - mae: 0.3230 - rmse: 0.4351 - val_loss: 0.2145 - val_mae: 0.3419 - val_rmse: 0.4631\n",
      "Epoch 4/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 25ms/step - loss: 0.1721 - mae: 0.3050 - rmse: 0.4148 - val_loss: 0.2173 - val_mae: 0.3421 - val_rmse: 0.4661\n",
      "Epoch 5/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1542 - mae: 0.2855 - rmse: 0.3926 - val_loss: 0.2201 - val_mae: 0.3428 - val_rmse: 0.4691\n",
      "Epoch 6/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 25ms/step - loss: 0.1309 - mae: 0.2594 - rmse: 0.3619 - val_loss: 0.2311 - val_mae: 0.3456 - val_rmse: 0.4807\n",
      "Epoch 7/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.1009 - mae: 0.2227 - rmse: 0.3177 - val_loss: 0.2475 - val_mae: 0.3526 - val_rmse: 0.4975\n",
      "Epoch 8/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 28ms/step - loss: 0.0746 - mae: 0.1886 - rmse: 0.2731 - val_loss: 0.2609 - val_mae: 0.3687 - val_rmse: 0.5108\n",
      "\u001b[1m3131/3131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      " 1번째 - MSE: 0.2156, RMSE: 0.4644, MAE: 0.3429, MAPE: 0.1187\n",
      "2번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 27ms/step - loss: 1.8318 - mae: 0.7799 - rmse: 1.1967 - val_loss: 0.2359 - val_mae: 0.3778 - val_rmse: 0.4856\n",
      "Epoch 2/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.2168 - mae: 0.3488 - rmse: 0.4656 - val_loss: 0.2141 - val_mae: 0.3450 - val_rmse: 0.4627\n",
      "Epoch 3/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1917 - mae: 0.3223 - rmse: 0.4378 - val_loss: 0.2136 - val_mae: 0.3414 - val_rmse: 0.4622\n",
      "Epoch 4/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1738 - mae: 0.3014 - rmse: 0.4169 - val_loss: 0.2164 - val_mae: 0.3271 - val_rmse: 0.4651\n",
      "Epoch 5/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1622 - mae: 0.2874 - rmse: 0.4027 - val_loss: 0.2166 - val_mae: 0.3298 - val_rmse: 0.4654\n",
      "Epoch 6/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1460 - mae: 0.2687 - rmse: 0.3821 - val_loss: 0.2248 - val_mae: 0.3306 - val_rmse: 0.4741\n",
      "Epoch 7/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1213 - mae: 0.2414 - rmse: 0.3483 - val_loss: 0.2347 - val_mae: 0.3370 - val_rmse: 0.4844\n",
      "Epoch 8/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.0923 - mae: 0.2077 - rmse: 0.3038 - val_loss: 0.2536 - val_mae: 0.3502 - val_rmse: 0.5036\n",
      "\u001b[1m3131/3131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      " 2번째 - MSE: 0.2132, RMSE: 0.4618, MAE: 0.3416, MAPE: 0.1174\n",
      "3번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 26ms/step - loss: 1.3537 - mae: 0.6745 - rmse: 1.0269 - val_loss: 0.2277 - val_mae: 0.3643 - val_rmse: 0.4772\n",
      "Epoch 2/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.2112 - mae: 0.3442 - rmse: 0.4596 - val_loss: 0.2166 - val_mae: 0.3464 - val_rmse: 0.4654\n",
      "Epoch 3/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 26ms/step - loss: 0.1871 - mae: 0.3220 - rmse: 0.4326 - val_loss: 0.2193 - val_mae: 0.3534 - val_rmse: 0.4683\n",
      "Epoch 4/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.1705 - mae: 0.3042 - rmse: 0.4129 - val_loss: 0.2282 - val_mae: 0.3590 - val_rmse: 0.4777\n",
      "Epoch 5/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.1485 - mae: 0.2808 - rmse: 0.3853 - val_loss: 0.2326 - val_mae: 0.3569 - val_rmse: 0.4823\n",
      "Epoch 6/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.1183 - mae: 0.2468 - rmse: 0.3439 - val_loss: 0.2433 - val_mae: 0.3585 - val_rmse: 0.4933\n",
      "Epoch 7/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.0891 - mae: 0.2109 - rmse: 0.2984 - val_loss: 0.2569 - val_mae: 0.3666 - val_rmse: 0.5069\n",
      "\u001b[1m3131/3131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      " 3번째 - MSE: 0.2150, RMSE: 0.4636, MAE: 0.3444, MAPE: 0.1189\n",
      "4번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 1.8757 - mae: 0.7884 - rmse: 1.2104 - val_loss: 0.2299 - val_mae: 0.3601 - val_rmse: 0.4794\n",
      "Epoch 2/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 28ms/step - loss: 0.2147 - mae: 0.3472 - rmse: 0.4634 - val_loss: 0.2164 - val_mae: 0.3501 - val_rmse: 0.4652\n",
      "Epoch 3/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.1903 - mae: 0.3245 - rmse: 0.4363 - val_loss: 0.2155 - val_mae: 0.3441 - val_rmse: 0.4642\n",
      "Epoch 4/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.1786 - mae: 0.3128 - rmse: 0.4226 - val_loss: 0.2145 - val_mae: 0.3414 - val_rmse: 0.4631\n",
      "Epoch 5/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.1671 - mae: 0.3008 - rmse: 0.4087 - val_loss: 0.2165 - val_mae: 0.3474 - val_rmse: 0.4653\n",
      "Epoch 6/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.1506 - mae: 0.2808 - rmse: 0.3881 - val_loss: 0.2176 - val_mae: 0.3360 - val_rmse: 0.4665\n",
      "Epoch 7/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.1274 - mae: 0.2538 - rmse: 0.3570 - val_loss: 0.2331 - val_mae: 0.3460 - val_rmse: 0.4828\n",
      "Epoch 8/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.0994 - mae: 0.2188 - rmse: 0.3153 - val_loss: 0.2485 - val_mae: 0.3543 - val_rmse: 0.4985\n",
      "Epoch 9/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.0743 - mae: 0.1840 - rmse: 0.2725 - val_loss: 0.2589 - val_mae: 0.3582 - val_rmse: 0.5089\n",
      "\u001b[1m3131/3131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      " 4번째 - MSE: 0.2158, RMSE: 0.4646, MAE: 0.3424, MAPE: 0.1219\n",
      "5번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 27ms/step - loss: 1.6809 - mae: 0.7472 - rmse: 1.1442 - val_loss: 0.2279 - val_mae: 0.3576 - val_rmse: 0.4774\n",
      "Epoch 2/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.2116 - mae: 0.3453 - rmse: 0.4600 - val_loss: 0.2188 - val_mae: 0.3458 - val_rmse: 0.4678\n",
      "Epoch 3/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.1896 - mae: 0.3242 - rmse: 0.4354 - val_loss: 0.2153 - val_mae: 0.3430 - val_rmse: 0.4640\n",
      "Epoch 4/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.1727 - mae: 0.3058 - rmse: 0.4155 - val_loss: 0.2170 - val_mae: 0.3431 - val_rmse: 0.4658\n",
      "Epoch 5/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 26ms/step - loss: 0.1545 - mae: 0.2853 - rmse: 0.3930 - val_loss: 0.2206 - val_mae: 0.3368 - val_rmse: 0.4697\n",
      "Epoch 6/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 27ms/step - loss: 0.1300 - mae: 0.2562 - rmse: 0.3606 - val_loss: 0.2389 - val_mae: 0.3484 - val_rmse: 0.4887\n",
      "Epoch 7/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 27ms/step - loss: 0.0988 - mae: 0.2177 - rmse: 0.3143 - val_loss: 0.2467 - val_mae: 0.3482 - val_rmse: 0.4967\n",
      "Epoch 8/50\n",
      "\u001b[1m1370/1370\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 27ms/step - loss: 0.0736 - mae: 0.1836 - rmse: 0.2713 - val_loss: 0.2641 - val_mae: 0.3596 - val_rmse: 0.5139\n",
      "\u001b[1m3131/3131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      " 5번째 - MSE: 0.2146, RMSE: 0.4633, MAE: 0.3423, MAPE: 0.1168\n"
     ]
    }
   ],
   "source": [
    "all_rmse = []\n",
    "all_mae = []\n",
    "all_mape = []\n",
    "all_mse = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    print(f\"{i+1}번째\\n\")\n",
    "\n",
    "\n",
    "    # 1. 데이터를 'random_state=i'로 분할 (매번 다른 분할)\n",
    "    train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42+i)\n",
    "    val_size_ratio = 1 / 8\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42+i)\n",
    "\n",
    "    user_encoder = LabelEncoder()\n",
    "    business_encoder = LabelEncoder()\n",
    "    train_df.loc[:, 'user_encoded'] = user_encoder.fit_transform(train_df['user_id'])\n",
    "    train_df.loc[:, 'business_encoded'] = business_encoder.fit_transform(train_df['business_id'])\n",
    "\n",
    "    user_mapping = {label: i for i, label in enumerate(user_encoder.classes_)}\n",
    "    business_mapping = {label: i for i, label in enumerate(business_encoder.classes_)}\n",
    "    val_df.loc[:, 'user_encoded'] = val_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "    val_df.loc[:, 'business_encoded'] = val_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "    test_df.loc[:, 'user_encoded'] = test_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "    test_df.loc[:, 'business_encoded'] = test_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "\n",
    "    num_users = len(user_encoder.classes_)\n",
    "    num_businesses = len(business_encoder.classes_)\n",
    "    \n",
    "    train_embeddings = np.vstack(train_df['embedding'].values)\n",
    "    val_embeddings = np.vstack(val_df['embedding'].values)\n",
    "    test_embeddings = np.vstack(test_df['embedding'].values)\n",
    "    gemini_embedding_dim = len(train_embeddings[0]) if len(train_embeddings) > 0 else 3072\n",
    "\n",
    "\n",
    "    final_model = build_hybrid_gemini_model(\n",
    "        num_users, num_businesses,\n",
    "        best_params['user_embedding_dim'], best_params['business_embedding_dim'],\n",
    "        gemini_embedding_dim,\n",
    "        best_params['user_biz_mlp_dims'], best_params['gemini_mlp_dims'],\n",
    "        best_params['final_mlp_dims'])\n",
    "    final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
    "                        loss='mse',\n",
    "                        metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mae'])\n",
    "    \n",
    "    early_stopping_callback = callbacks.EarlyStopping(\n",
    "        monitor='val_rmse',\n",
    "        patience=5,\n",
    "        min_delta=0.0005,\n",
    "        mode='min',\n",
    "        restore_best_weights=True)\n",
    "    model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_SAVE_PATH,\n",
    "        monitor='val_rmse',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=0)\n",
    "\n",
    "\n",
    "    history = final_model.fit(\n",
    "        {'user_id': train_df['user_encoded'],\n",
    "         'business_id': train_df['business_encoded'],\n",
    "         'gemini_embedding': train_embeddings},\n",
    "        train_df['review_stars'],\n",
    "        batch_size=best_params['batch_size'],\n",
    "        epochs=50,\n",
    "        validation_data=(\n",
    "            {'user_id': val_df['user_encoded'],\n",
    "             'business_id': val_df['business_encoded'],\n",
    "             'gemini_embedding': val_embeddings},\n",
    "            val_df['review_stars']\n",
    "        ),\n",
    "        callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
    "        verbose=1)\n",
    "\n",
    "    test_predictions = final_model.predict(\n",
    "        {'user_id': test_df['user_encoded'],\n",
    "         'business_id': test_df['business_encoded'],\n",
    "         'gemini_embedding': test_embeddings}\n",
    "    ).flatten()\n",
    "    true_ratings = test_df['review_stars'].values\n",
    "\n",
    "    mse = mean_squared_error(true_ratings, test_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "    mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "    \n",
    "    all_mse.append(mse)\n",
    "    all_rmse.append(rmse)\n",
    "    all_mae.append(mae)\n",
    "    all_mape.append(mape)\n",
    "    \n",
    "    print(f\" {i+1}번째 - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8af5c-96f6-49aa-ae96-a965ec8a5ddd",
   "metadata": {},
   "source": [
    "최종 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee70fba-a0af-400a-982c-babd86e2c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5회 실험 최종 결과 요약\n",
      "\n",
      "평균 MSE: 0.2149\n",
      "MSE 표준편차: 0.00092\n",
      "평균 RMSE: 0.4635\n",
      "RMSE 표준편차: 0.00099\n",
      "평균 MAE: 0.3427\n",
      "MAE 표준편차: 0.00093\n",
      "평균 MAPE: 0.12%\n",
      "MAPE 표준편차: 0.00176\n"
     ]
    }
   ],
   "source": [
    "print(\"5회 실험 최종 결과 요약\\n\")\n",
    "\n",
    "mean_rmse = np.mean(all_rmse)\n",
    "std_rmse = np.std(all_rmse)\n",
    "mean_mae = np.mean(all_mae)\n",
    "std_mae = np.std(all_mae)\n",
    "mean_mape = np.mean(all_mape)\n",
    "std_mape = np.std(all_mape)\n",
    "all_mse = [x**2 for x in all_rmse]\n",
    "mean_mse = np.mean(all_mse)\n",
    "std_mse = np.std(all_mse)\n",
    "\n",
    "print(f\"평균 MSE: {mean_mse:.4f}\")\n",
    "print(f\"MSE 표준편차: {std_mse:.5f}\")\n",
    "\n",
    "print(f\"평균 RMSE: {mean_rmse:.4f}\")\n",
    "print(f\"RMSE 표준편차: {std_rmse:.5f}\")\n",
    "\n",
    "print(f\"평균 MAE: {mean_mae:.4f}\")\n",
    "print(f\"MAE 표준편차: {std_mae:.5f}\")\n",
    "\n",
    "print(f\"평균 MAPE: {mean_mape:.2f}%\")\n",
    "print(f\"MAPE 표준편차: {std_mape:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a2a4-646e-4b7c-95a6-ee5c14265ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
