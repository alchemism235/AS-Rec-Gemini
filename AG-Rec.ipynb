{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a914c52a-4cfb-4113-908e-2118452e8ba7",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b38ca08-2950-45f2-aba9-bbcb59c0065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d9c16-4e3c-43a6-87a7-bb1e76d56f0e",
   "metadata": {},
   "source": [
    "파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c48a4fb-12c8-40c3-bb21-4397658a417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 데이터 로드\n"
     ]
    }
   ],
   "source": [
    "PARQUET_PATH = 'review_data_optimized.parquet'\n",
    "MODEL_SAVE_PATH = 'final_best_hybrid_gemini_model.keras'\n",
    "\n",
    "best_params = {\n",
    "    'user_embedding_dim': 64,\n",
    "    'business_embedding_dim': 64,\n",
    "    'gemini_mlp_dims': [1536, 768, 384],\n",
    "    'user_biz_mlp_dims': [128, 64],\n",
    "    'final_mlp_dims': [256, 128, 64],\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 128\n",
    "}\n",
    "\n",
    "df = pd.read_parquet(PARQUET_PATH)\n",
    "print(\" 데이터 로드\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce5f55-f715-4ac8-8208-975a0b54513a",
   "metadata": {},
   "source": [
    "데이터 분할 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78df1c1f-75a0-4f97-96d8-828787a3478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 447796\n",
      "학습 데이터 수: 313456 (70.00%)\n",
      "검증 데이터 수: 44780 (10.00%)\n",
      "테스트 데이터 수: 89560 (20.00%)\n",
      "제미니 임베딩 차원: 3072\n"
     ]
    }
   ],
   "source": [
    "df_processed = df[['user_id', 'business_id', 'stars', 'embedding']].copy()\n",
    "\n",
    "# 데이터 7:1:2로 분할\n",
    "train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "val_size_ratio = 1 / 8 \n",
    "train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42)\n",
    "\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "business_encoder = LabelEncoder()\n",
    "\n",
    "train_df.loc[:, 'user_encoded'] = user_encoder.fit_transform(train_df['user_id'])\n",
    "train_df.loc[:, 'business_encoded'] = business_encoder.fit_transform(train_df['business_id'])\n",
    "\n",
    "\n",
    "user_mapping = {label: i for i, label in enumerate(user_encoder.classes_)}\n",
    "business_mapping = {label: i for i, label in enumerate(business_encoder.classes_)}\n",
    "\n",
    "\n",
    "val_df.loc[:, 'user_encoded'] = val_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "val_df.loc[:, 'business_encoded'] = val_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "\n",
    "test_df.loc[:, 'user_encoded'] = test_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "test_df.loc[:, 'business_encoded'] = test_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "\n",
    "num_users = len(user_encoder.classes_)\n",
    "num_businesses = len(business_encoder.classes_)\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df_processed)}\")\n",
    "print(f\"학습 데이터 수: {len(train_df)} ({len(train_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"검증 데이터 수: {len(val_df)} ({len(val_df)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"테스트 데이터 수: {len(test_df)} ({len(test_df)/len(df_processed)*100:.2f}%)\")\n",
    "\n",
    "train_embeddings = np.array(train_df['embedding'].tolist())\n",
    "val_embeddings = np.array(val_df['embedding'].tolist())\n",
    "test_embeddings = np.array(test_df['embedding'].tolist())\n",
    "\n",
    "gemini_embedding_dim = len(train_df['embedding'].iloc[0]) if not train_df.empty else 3072\n",
    "print(f\"제미니 임베딩 차원: {gemini_embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef063717-5e9d-4962-97c0-188ca09912ad",
   "metadata": {},
   "source": [
    "모델 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e29248-1d74-41f2-881c-73fe199c1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_gemini_model(num_users, num_businesses, user_embedding_dim, business_embedding_dim,\n",
    "                             gemini_embedding_dim, user_biz_mlp_dims, gemini_mlp_dims, final_mlp_dims):\n",
    "    \n",
    "    # 사용자-비즈니스 상호작용 모듈\n",
    "    user_input = keras.Input(shape=(1,), name='user_id')\n",
    "    business_input = keras.Input(shape=(1,), name='business_id')\n",
    "    user_embedding = layers.Embedding(num_users, user_embedding_dim, name='user_embedding')(user_input)\n",
    "    user_vec = layers.Flatten()(user_embedding)\n",
    "    business_embedding = layers.Embedding(num_businesses, business_embedding_dim, name='business_embedding')(business_input)\n",
    "    business_vec = layers.Flatten()(business_embedding)\n",
    "    combined_vec = layers.concatenate([user_vec, business_vec], axis=1)\n",
    "    interaction_features = combined_vec\n",
    "    for dim in user_biz_mlp_dims:\n",
    "        interaction_features = layers.Dense(dim, activation='relu')(interaction_features)\n",
    "\n",
    "    # 제미니 임베딩 모듈\n",
    "    gemini_input = keras.Input(shape=(gemini_embedding_dim,), name='gemini_embedding')\n",
    "    gemini_features = gemini_input\n",
    "    for dim in gemini_mlp_dims:\n",
    "        gemini_features = layers.Dense(dim, activation='relu')(gemini_features)\n",
    "    \n",
    "    # 최종 예측 모듈\n",
    "    final_combined_features = layers.concatenate([interaction_features, gemini_features], axis=1)\n",
    "    predicted_rating = final_combined_features\n",
    "    for dim in final_mlp_dims:\n",
    "        predicted_rating = layers.Dense(dim, activation='relu')(predicted_rating)\n",
    "    predicted_rating = layers.Dense(1, activation='linear', name='output_rating')(predicted_rating)\n",
    "    \n",
    "    model = models.Model(inputs=[user_input, business_input, gemini_input], outputs=predicted_rating)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8af5c-96f6-49aa-ae96-a965ec8a5ddd",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee70fba-a0af-400a-982c-babd86e2c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "파라미터 : {'user_embedding_dim': 64, 'business_embedding_dim': 64, 'gemini_mlp_dims': [1536, 768, 384], 'user_biz_mlp_dims': [128, 64], 'final_mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 128}\n",
      "==================================================\n",
      "Epoch 1/50\n",
      "\u001b[1m2447/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5193 - mae: 0.4833 - rmse: 0.6662\n",
      "Epoch 1: val_rmse improved from inf to 0.48354, saving model to final_best_hybrid_gemini_model.keras\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 19ms/step - loss: 0.5191 - mae: 0.4832 - rmse: 0.6661 - val_loss: 0.2338 - val_mae: 0.3726 - val_rmse: 0.4835\n",
      "Epoch 2/50\n",
      "\u001b[1m2447/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.2135 - mae: 0.3565 - rmse: 0.4620\n",
      "Epoch 2: val_rmse improved from 0.48354 to 0.47346, saving model to final_best_hybrid_gemini_model.keras\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 19ms/step - loss: 0.2135 - mae: 0.3565 - rmse: 0.4620 - val_loss: 0.2242 - val_mae: 0.3651 - val_rmse: 0.4735\n",
      "Epoch 3/50\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1623 - mae: 0.3054 - rmse: 0.4028\n",
      "Epoch 3: val_rmse did not improve from 0.47346\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 19ms/step - loss: 0.1623 - mae: 0.3054 - rmse: 0.4028 - val_loss: 0.2418 - val_mae: 0.3819 - val_rmse: 0.4918\n",
      "Epoch 4/50\n",
      "\u001b[1m2448/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1125 - mae: 0.2506 - rmse: 0.3353\n",
      "Epoch 4: val_rmse did not improve from 0.47346\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 19ms/step - loss: 0.1125 - mae: 0.2506 - rmse: 0.3353 - val_loss: 0.2575 - val_mae: 0.3838 - val_rmse: 0.5074\n",
      "Epoch 5/50\n",
      "\u001b[1m2447/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0775 - mae: 0.2004 - rmse: 0.2783\n",
      "Epoch 5: val_rmse did not improve from 0.47346\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 19ms/step - loss: 0.0775 - mae: 0.2004 - rmse: 0.2783 - val_loss: 0.2595 - val_mae: 0.3742 - val_rmse: 0.5094\n",
      "Epoch 6/50\n",
      "\u001b[1m2448/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0543 - mae: 0.1481 - rmse: 0.2329\n",
      "Epoch 6: val_rmse did not improve from 0.47346\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 19ms/step - loss: 0.0543 - mae: 0.1481 - rmse: 0.2329 - val_loss: 0.2761 - val_mae: 0.3554 - val_rmse: 0.5254\n",
      "Epoch 7/50\n",
      "\u001b[1m2448/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0420 - mae: 0.1133 - rmse: 0.2049\n",
      "Epoch 7: val_rmse did not improve from 0.47346\n",
      "\u001b[1m2449/2449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 19ms/step - loss: 0.0420 - mae: 0.1133 - rmse: 0.2049 - val_loss: 0.2862 - val_mae: 0.3499 - val_rmse: 0.5350\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"파라미터 : {best_params}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 최종 모델\n",
    "final_model = build_hybrid_gemini_model(\n",
    "    num_users, num_businesses,\n",
    "    best_params['user_embedding_dim'], best_params['business_embedding_dim'],\n",
    "    gemini_embedding_dim,\n",
    "    best_params['user_biz_mlp_dims'], best_params['gemini_mlp_dims'],\n",
    "    best_params['final_mlp_dims']\n",
    ")\n",
    "\n",
    "final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
    "                    loss='mse',\n",
    "                    metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mae'])\n",
    "\n",
    "early_stopping_callback = callbacks.EarlyStopping(\n",
    "    monitor='val_rmse',\n",
    "    patience=5,\n",
    "    min_delta=0.0005,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_SAVE_PATH,\n",
    "    monitor='val_rmse',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "history = final_model.fit(\n",
    "    {'user_id': train_df['user_encoded'],\n",
    "     'business_id': train_df['business_encoded'],\n",
    "     'gemini_embedding': train_embeddings},\n",
    "    train_df['stars'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    epochs=50,\n",
    "    validation_data=(\n",
    "        {'user_id': val_df['user_encoded'],\n",
    "         'business_id': val_df['business_encoded'],\n",
    "         'gemini_embedding': val_embeddings},\n",
    "        val_df['stars']\n",
    "    ),\n",
    "    callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e5c4f-8840-409a-9e54-53faf817caa0",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d0c837c-a84f-41a1-8538-cc45361c6d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 최적 파라미터 : final_best_hybrid_gemini_model.keras\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step\n",
      "파라미터 : {'user_embedding_dim': 64, 'business_embedding_dim': 64, 'gemini_mlp_dims': [1536, 768, 384], 'user_biz_mlp_dims': [128, 64], 'final_mlp_dims': [256, 128, 64], 'learning_rate': 0.001, 'batch_size': 128}\n",
      "Mean Squared Error (MSE): 0.2210\n",
      "Root Mean Squared Error (RMSE): 0.4701\n",
      "Mean Absolute Error (MAE): 0.3638\n",
      "Mean Absolute Percentage Error (MAPE): 0.1226\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    final_model = keras.models.load_model(MODEL_SAVE_PATH)\n",
    "    print(f\" 최적 파라미터 : {MODEL_SAVE_PATH}\")\n",
    "else:\n",
    "    print(f\"최적 파라미터 찾을 수 없음\")\n",
    "\n",
    "test_predictions = final_model.predict(\n",
    "    {'user_id': test_df['user_encoded'],\n",
    "     'business_id': test_df['business_encoded'],\n",
    "     'gemini_embedding': test_embeddings}\n",
    ").flatten()\n",
    "\n",
    "true_ratings = test_df['stars'].values\n",
    "\n",
    "mse = mean_squared_error(true_ratings, test_predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "\n",
    "\n",
    "print(f\"파라미터 : {best_params}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cccbd4-e362-4477-afeb-799f3d956491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
