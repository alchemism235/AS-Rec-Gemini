{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a914c52a-4cfb-4113-908e-2118452e8ba7",
   "metadata": {},
   "source": [
    "라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b38ca08-2950-45f2-aba9-bbcb59c0065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83d9c16-4e3c-43a6-87a7-bb1e76d56f0e",
   "metadata": {},
   "source": [
    "파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c48a4fb-12c8-40c3-bb21-4397658a417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 데이터 로드\n"
     ]
    }
   ],
   "source": [
    "PARQUET_PATH = 'review_data_optimized.parquet'\n",
    "MODEL_SAVE_PATH = 'final_best_hybrid_gemini_model.keras'\n",
    "\n",
    "best_params = {\n",
    "    'user_embedding_dim': 128,\n",
    "    'business_embedding_dim': 32,\n",
    "    'gemini_mlp_dims': [1536, 768, 384, 192],\n",
    "    'user_biz_mlp_dims': [128, 64],\n",
    "    'final_mlp_dims': [64, 32],\n",
    "    'learning_rate': 0.0001,\n",
    "    'batch_size': 256\n",
    "}\n",
    "\n",
    "df = pd.read_parquet(PARQUET_PATH)\n",
    "print(\" 데이터 로드\")\n",
    "df_processed = df[['user_id', 'business_id', 'stars', 'embedding']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be44d46-947c-420c-89ca-7c0a94d8c496",
   "metadata": {},
   "source": [
    "모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8372b8f6-7b5c-4fd9-bb55-fc7aae873b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_gemini_model(num_users, num_businesses, user_embedding_dim, business_embedding_dim,\n",
    "                              gemini_embedding_dim, user_biz_mlp_dims, gemini_mlp_dims, final_mlp_dims):\n",
    "    \n",
    "    # 사용자-비즈니스 상호작용 모듈\n",
    "    user_input = keras.Input(shape=(1,), name='user_id')\n",
    "    business_input = keras.Input(shape=(1,), name='business_id')\n",
    "\n",
    "    user_embedding = layers.Embedding(num_users, user_embedding_dim, name='user_embedding')(user_input)\n",
    "    user_vec = layers.Flatten()(user_embedding)\n",
    "\n",
    "    business_embedding = layers.Embedding(num_businesses, business_embedding_dim, name='business_embedding')(business_input)\n",
    "    business_vec = layers.Flatten()(business_embedding)\n",
    "\n",
    "    combined_vec = layers.concatenate([user_vec, business_vec], axis=1)\n",
    "    interaction_features = combined_vec\n",
    "    for dim in user_biz_mlp_dims:\n",
    "        interaction_features = layers.Dense(dim, activation='relu')(interaction_features)\n",
    "\n",
    "    # Gemini 임베딩 모듈\n",
    "    gemini_input = keras.Input(shape=(gemini_embedding_dim,), name='gemini_embedding')\n",
    "    gemini_features = gemini_input\n",
    "    for dim in gemini_mlp_dims:\n",
    "        gemini_features = layers.Dense(dim, activation='relu')(gemini_features)\n",
    "    \n",
    "    # 최종 예측 모듈\n",
    "    final_combined_features = layers.concatenate([interaction_features, gemini_features], axis=1)\n",
    "\n",
    "    predicted_rating = final_combined_features\n",
    "    for dim in final_mlp_dims:\n",
    "        predicted_rating = layers.Dense(dim, activation='relu')(predicted_rating)\n",
    "    predicted_rating = layers.Dense(1, activation='linear', name='output_rating')(predicted_rating)\n",
    "    \n",
    "    model = models.Model(inputs=[user_input, business_input, gemini_input],\n",
    "                         outputs=predicted_rating)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecce5f55-f715-4ac8-8208-975a0b54513a",
   "metadata": {},
   "source": [
    "데이터 분할 / 5회 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78df1c1f-75a0-4f97-96d8-828787a3478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\alche\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "1번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 26ms/step - loss: 1.8078 - mae: 0.7990 - rmse: 1.1916 - val_loss: 0.2404 - val_mae: 0.3810 - val_rmse: 0.4903\n",
      "Epoch 2/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - loss: 0.2272 - mae: 0.3684 - rmse: 0.4766 - val_loss: 0.2223 - val_mae: 0.3666 - val_rmse: 0.4715\n",
      "Epoch 3/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.1972 - mae: 0.3396 - rmse: 0.4441 - val_loss: 0.2229 - val_mae: 0.3540 - val_rmse: 0.4721\n",
      "Epoch 4/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.1801 - mae: 0.3195 - rmse: 0.4243 - val_loss: 0.2208 - val_mae: 0.3541 - val_rmse: 0.4699\n",
      "Epoch 5/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 0.1671 - mae: 0.3053 - rmse: 0.4087 - val_loss: 0.2237 - val_mae: 0.3561 - val_rmse: 0.4729\n",
      "Epoch 6/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - loss: 0.1527 - mae: 0.2898 - rmse: 0.3907 - val_loss: 0.2286 - val_mae: 0.3607 - val_rmse: 0.4781\n",
      "Epoch 7/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 26ms/step - loss: 0.1308 - mae: 0.2656 - rmse: 0.3616 - val_loss: 0.2404 - val_mae: 0.3767 - val_rmse: 0.4903\n",
      "Epoch 8/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - loss: 0.1032 - mae: 0.2325 - rmse: 0.3212 - val_loss: 0.2494 - val_mae: 0.3680 - val_rmse: 0.4994\n",
      "Epoch 9/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 0.0799 - mae: 0.2011 - rmse: 0.2826 - val_loss: 0.2582 - val_mae: 0.3688 - val_rmse: 0.5081\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      " 1번째 - MSE: 0.2197, RMSE: 0.4687, MAE: 0.3534, MAPE: 0.1183\n",
      "2번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 26ms/step - loss: 1.3913 - mae: 0.7075 - rmse: 1.0448 - val_loss: 0.2427 - val_mae: 0.3771 - val_rmse: 0.4927\n",
      "Epoch 2/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - loss: 0.2208 - mae: 0.3634 - rmse: 0.4699 - val_loss: 0.2236 - val_mae: 0.3680 - val_rmse: 0.4728\n",
      "Epoch 3/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 0.1949 - mae: 0.3377 - rmse: 0.4414 - val_loss: 0.2307 - val_mae: 0.3737 - val_rmse: 0.4803\n",
      "Epoch 4/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 26ms/step - loss: 0.1792 - mae: 0.3212 - rmse: 0.4233 - val_loss: 0.2208 - val_mae: 0.3546 - val_rmse: 0.4699\n",
      "Epoch 5/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.1632 - mae: 0.3039 - rmse: 0.4039 - val_loss: 0.2247 - val_mae: 0.3543 - val_rmse: 0.4740\n",
      "Epoch 6/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 0.1432 - mae: 0.2820 - rmse: 0.3784 - val_loss: 0.2341 - val_mae: 0.3600 - val_rmse: 0.4838\n",
      "Epoch 7/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 0.1166 - mae: 0.2510 - rmse: 0.3415 - val_loss: 0.2461 - val_mae: 0.3683 - val_rmse: 0.4961\n",
      "Epoch 8/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 0.0885 - mae: 0.2153 - rmse: 0.2974 - val_loss: 0.2653 - val_mae: 0.3776 - val_rmse: 0.5150\n",
      "Epoch 9/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 0.0689 - mae: 0.1875 - rmse: 0.2624 - val_loss: 0.2651 - val_mae: 0.3794 - val_rmse: 0.5149\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      " 2번째 - MSE: 0.2193, RMSE: 0.4683, MAE: 0.3538, MAPE: 0.1183\n",
      "3번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 1.5890 - mae: 0.7490 - rmse: 1.1164 - val_loss: 0.2354 - val_mae: 0.3767 - val_rmse: 0.4852\n",
      "Epoch 2/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.2194 - mae: 0.3620 - rmse: 0.4684 - val_loss: 0.2208 - val_mae: 0.3621 - val_rmse: 0.4699\n",
      "Epoch 3/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1910 - mae: 0.3312 - rmse: 0.4370 - val_loss: 0.2195 - val_mae: 0.3492 - val_rmse: 0.4686\n",
      "Epoch 4/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1741 - mae: 0.3126 - rmse: 0.4172 - val_loss: 0.2189 - val_mae: 0.3538 - val_rmse: 0.4678\n",
      "Epoch 5/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 0.1567 - mae: 0.2943 - rmse: 0.3958 - val_loss: 0.2278 - val_mae: 0.3576 - val_rmse: 0.4773\n",
      "Epoch 6/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 0.1305 - mae: 0.2649 - rmse: 0.3613 - val_loss: 0.2374 - val_mae: 0.3608 - val_rmse: 0.4872\n",
      "Epoch 7/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 0.1022 - mae: 0.2306 - rmse: 0.3197 - val_loss: 0.2514 - val_mae: 0.3719 - val_rmse: 0.5014\n",
      "Epoch 8/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.0782 - mae: 0.1984 - rmse: 0.2796 - val_loss: 0.2605 - val_mae: 0.3705 - val_rmse: 0.5104\n",
      "Epoch 9/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.0608 - mae: 0.1724 - rmse: 0.2465 - val_loss: 0.2727 - val_mae: 0.3800 - val_rmse: 0.5222\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      " 3번째 - MSE: 0.2207, RMSE: 0.4698, MAE: 0.3543, MAPE: 0.1166\n",
      "4번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - loss: 1.6505 - mae: 0.7660 - rmse: 1.1385 - val_loss: 0.2453 - val_mae: 0.3795 - val_rmse: 0.4953\n",
      "Epoch 2/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.2254 - mae: 0.3689 - rmse: 0.4747 - val_loss: 0.2228 - val_mae: 0.3653 - val_rmse: 0.4721\n",
      "Epoch 3/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1966 - mae: 0.3416 - rmse: 0.4434 - val_loss: 0.2217 - val_mae: 0.3618 - val_rmse: 0.4708\n",
      "Epoch 4/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1810 - mae: 0.3249 - rmse: 0.4255 - val_loss: 0.2214 - val_mae: 0.3609 - val_rmse: 0.4705\n",
      "Epoch 5/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1652 - mae: 0.3068 - rmse: 0.4065 - val_loss: 0.2231 - val_mae: 0.3563 - val_rmse: 0.4723\n",
      "Epoch 6/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1424 - mae: 0.2822 - rmse: 0.3773 - val_loss: 0.2294 - val_mae: 0.3596 - val_rmse: 0.4790\n",
      "Epoch 7/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1146 - mae: 0.2487 - rmse: 0.3385 - val_loss: 0.2437 - val_mae: 0.3648 - val_rmse: 0.4937\n",
      "Epoch 8/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.0883 - mae: 0.2146 - rmse: 0.2972 - val_loss: 0.2561 - val_mae: 0.3722 - val_rmse: 0.5061\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      " 4번째 - MSE: 0.2207, RMSE: 0.4698, MAE: 0.3613, MAPE: 0.1168\n",
      "5번째\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - loss: 1.7465 - mae: 0.7874 - rmse: 1.1712 - val_loss: 0.2442 - val_mae: 0.3892 - val_rmse: 0.4942\n",
      "Epoch 2/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.2251 - mae: 0.3679 - rmse: 0.4744 - val_loss: 0.2259 - val_mae: 0.3656 - val_rmse: 0.4753\n",
      "Epoch 3/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 0.1977 - mae: 0.3418 - rmse: 0.4446 - val_loss: 0.2219 - val_mae: 0.3638 - val_rmse: 0.4710\n",
      "Epoch 4/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.1834 - mae: 0.3264 - rmse: 0.4282 - val_loss: 0.2200 - val_mae: 0.3561 - val_rmse: 0.4691\n",
      "Epoch 5/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1695 - mae: 0.3116 - rmse: 0.4118 - val_loss: 0.2221 - val_mae: 0.3571 - val_rmse: 0.4712\n",
      "Epoch 6/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1532 - mae: 0.2935 - rmse: 0.3914 - val_loss: 0.2309 - val_mae: 0.3677 - val_rmse: 0.4805\n",
      "Epoch 7/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 0.1291 - mae: 0.2668 - rmse: 0.3593 - val_loss: 0.2392 - val_mae: 0.3654 - val_rmse: 0.4891\n",
      "Epoch 8/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.1020 - mae: 0.2329 - rmse: 0.3193 - val_loss: 0.2558 - val_mae: 0.3733 - val_rmse: 0.5058\n",
      "Epoch 9/50\n",
      "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 0.0784 - mae: 0.2014 - rmse: 0.2799 - val_loss: 0.2647 - val_mae: 0.3805 - val_rmse: 0.5145\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      " 5번째 - MSE: 0.2166, RMSE: 0.4654, MAE: 0.3536, MAPE: 0.1157\n"
     ]
    }
   ],
   "source": [
    "all_rmse = []\n",
    "all_mae = []\n",
    "all_mape = []\n",
    "all_mse = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    print(f\"{i+1}번째\\n\")\n",
    "\n",
    "\n",
    "    # 1. 데이터를 'random_state=i'로 분할 (매번 다른 분할)\n",
    "    train_val_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42+i)\n",
    "    val_size_ratio = 1 / 8\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=val_size_ratio, random_state=42+i)\n",
    "\n",
    "    user_encoder = LabelEncoder()\n",
    "    business_encoder = LabelEncoder()\n",
    "    train_df.loc[:, 'user_encoded'] = user_encoder.fit_transform(train_df['user_id'])\n",
    "    train_df.loc[:, 'business_encoded'] = business_encoder.fit_transform(train_df['business_id'])\n",
    "\n",
    "    user_mapping = {label: i for i, label in enumerate(user_encoder.classes_)}\n",
    "    business_mapping = {label: i for i, label in enumerate(business_encoder.classes_)}\n",
    "    val_df.loc[:, 'user_encoded'] = val_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "    val_df.loc[:, 'business_encoded'] = val_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "    test_df.loc[:, 'user_encoded'] = test_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "    test_df.loc[:, 'business_encoded'] = test_df['business_id'].map(business_mapping).fillna(-1).astype(int)\n",
    "\n",
    "    num_users = len(user_encoder.classes_)\n",
    "    num_businesses = len(business_encoder.classes_)\n",
    "    \n",
    "    train_embeddings = np.vstack(train_df['embedding'].values)\n",
    "    val_embeddings = np.vstack(val_df['embedding'].values)\n",
    "    test_embeddings = np.vstack(test_df['embedding'].values)\n",
    "    gemini_embedding_dim = len(train_embeddings[0]) if len(train_embeddings) > 0 else 3072\n",
    "\n",
    "\n",
    "    final_model = build_hybrid_gemini_model(\n",
    "        num_users, num_businesses,\n",
    "        best_params['user_embedding_dim'], best_params['business_embedding_dim'],\n",
    "        gemini_embedding_dim,\n",
    "        best_params['user_biz_mlp_dims'], best_params['gemini_mlp_dims'],\n",
    "        best_params['final_mlp_dims'])\n",
    "    final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=best_params['learning_rate']),\n",
    "                        loss='mse',\n",
    "                        metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse'), 'mae'])\n",
    "    \n",
    "    early_stopping_callback = callbacks.EarlyStopping(\n",
    "        monitor='val_rmse',\n",
    "        patience=5,\n",
    "        min_delta=0.0005,\n",
    "        mode='min',\n",
    "        restore_best_weights=True)\n",
    "    model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "        filepath=MODEL_SAVE_PATH,\n",
    "        monitor='val_rmse',\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        verbose=0)\n",
    "\n",
    "\n",
    "    history = final_model.fit(\n",
    "        {'user_id': train_df['user_encoded'],\n",
    "         'business_id': train_df['business_encoded'],\n",
    "         'gemini_embedding': train_embeddings},\n",
    "        train_df['stars'],\n",
    "        batch_size=best_params['batch_size'],\n",
    "        epochs=50,\n",
    "        validation_data=(\n",
    "            {'user_id': val_df['user_encoded'],\n",
    "             'business_id': val_df['business_encoded'],\n",
    "             'gemini_embedding': val_embeddings},\n",
    "            val_df['stars']\n",
    "        ),\n",
    "        callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
    "        verbose=1)\n",
    "\n",
    "    test_predictions = final_model.predict(\n",
    "        {'user_id': test_df['user_encoded'],\n",
    "         'business_id': test_df['business_encoded'],\n",
    "         'gemini_embedding': test_embeddings}\n",
    "    ).flatten()\n",
    "    true_ratings = test_df['stars'].values\n",
    "\n",
    "    mse = mean_squared_error(true_ratings, test_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(true_ratings, test_predictions)\n",
    "    mape = mean_absolute_percentage_error(true_ratings, test_predictions)\n",
    "    \n",
    "    all_mse.append(mse)\n",
    "    all_rmse.append(rmse)\n",
    "    all_mae.append(mae)\n",
    "    all_mape.append(mape)\n",
    "    \n",
    "    print(f\" {i+1}번째 - MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, MAPE: {mape:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8af5c-96f6-49aa-ae96-a965ec8a5ddd",
   "metadata": {},
   "source": [
    "최종 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fee70fba-a0af-400a-982c-babd86e2c266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5회 실험 최종 결과 요약\n",
      "\n",
      "평균 MSE: 0.2194\n",
      "MSE 표준편차: 0.00152\n",
      "평균 RMSE: 0.4684\n",
      "RMSE 표준편차: 0.00162\n",
      "평균 MAE: 0.3553\n",
      "MAE 표준편차: 0.00300\n",
      "평균 MAPE: 0.1171\n",
      "MAPE 표준편차: 0.00101\n"
     ]
    }
   ],
   "source": [
    "print(\"5회 실험 최종 결과 요약\\n\")\n",
    "\n",
    "mean_rmse = np.mean(all_rmse)\n",
    "std_rmse = np.std(all_rmse)\n",
    "mean_mae = np.mean(all_mae)\n",
    "std_mae = np.std(all_mae)\n",
    "mean_mape = np.mean(all_mape)\n",
    "std_mape = np.std(all_mape)\n",
    "all_mse = [x**2 for x in all_rmse]\n",
    "mean_mse = np.mean(all_mse)\n",
    "std_mse = np.std(all_mse)\n",
    "\n",
    "print(f\"평균 MSE: {mean_mse:.4f}\")\n",
    "print(f\"MSE 표준편차: {std_mse:.5f}\")\n",
    "\n",
    "print(f\"평균 RMSE: {mean_rmse:.4f}\")\n",
    "print(f\"RMSE 표준편차: {std_rmse:.5f}\")\n",
    "\n",
    "print(f\"평균 MAE: {mean_mae:.4f}\")\n",
    "print(f\"MAE 표준편차: {std_mae:.5f}\")\n",
    "\n",
    "print(f\"평균 MAPE: {mean_mape:.4f}\")\n",
    "print(f\"MAPE 표준편차: {std_mape:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2199a2a4-646e-4b7c-95a6-ee5c14265ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
